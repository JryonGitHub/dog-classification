ssh://zhangxu@114.212.81.211:22/home/zhangxu/anaconda3/bin/python -u /home/zhangxu/python_project/dog_classify/code/train.py
Using TensorFlow backend.
class labels are: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '57', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '94', '95', '97', '101', '109', '111', '114', '115', '120', '123', '126', '127', '128', '129', '132', '133']
Found 8153 images belonging to 100 classes.
{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14, '16': 15, '17': 16, '18': 17, '19': 18, '20': 19, '21': 20, '22': 21, '23': 22, '24': 23, '25': 24, '26': 25, '27': 26, '28': 27, '29': 28, '30': 29, '31': 30, '32': 31, '33': 32, '34': 33, '35': 34, '36': 35, '37': 36, '38': 37, '39': 38, '40': 39, '41': 40, '42': 41, '43': 42, '45': 43, '46': 44, '47': 45, '48': 46, '49': 47, '50': 48, '51': 49, '52': 50, '53': 51, '54': 52, '57': 53, '59': 54, '60': 55, '61': 56, '62': 57, '63': 58, '64': 59, '65': 60, '66': 61, '67': 62, '68': 63, '69': 64, '70': 65, '71': 66, '72': 67, '73': 68, '74': 69, '75': 70, '76': 71, '77': 72, '78': 73, '79': 74, '80': 75, '81': 76, '82': 77, '83': 78, '84': 79, '85': 80, '86': 81, '87': 82, '88': 83, '94': 84, '95': 85, '97': 86, '101': 87, '109': 88, '111': 89, '114': 90, '115': 91, '120': 92, '123': 93, '126': 94, '127': 95, '128': 96, '129': 97, '132': 98, '133': 99}
Found 10551 images belonging to 100 classes.
2017-07-07 21:31:03.949331: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-07 21:31:03.949389: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-07 21:31:03.949402: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-07 21:31:03.949413: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-07 21:31:03.949422: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-07-07 21:31:05.900538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties:
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:02:00.0
Total memory: 10.91GiB
Free memory: 10.76GiB
2017-07-07 21:31:06.226591: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x4731610 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-07-07 21:31:06.227889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 1 with properties:
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:81:00.0
Total memory: 10.91GiB
Free memory: 10.76GiB
2017-07-07 21:31:06.228032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:832] Peer access not supported between device ordinals 0 and 1
2017-07-07 21:31:06.228060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:832] Peer access not supported between device ordinals 1 and 0
2017-07-07 21:31:06.228088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 1
2017-07-07 21:31:06.228105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y N
2017-07-07 21:31:06.228115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   N Y
2017-07-07 21:31:06.228240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0)
2017-07-07 21:31:06.228323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:81:00.0)
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, None, None, 3)     0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, None, None, 64)    1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, None, None, 64)    36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, None, None, 64)    0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, None, None, 128)   73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, None, None, 128)   147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, None, None, 128)   0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, None, None, 256)   295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, None, None, 256)   0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, None, None, 512)   1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, None, None, 512)   0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, None, None, 512)   0
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
/home/zhangxu/python_project/dog_classify/code/model1.py:89: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("im..., outputs=Tensor("de...)`
  my_model = Model(input=input, output=x)
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
image_input (InputLayer)     (None, 128, 128, 3)       0
_________________________________________________________________
vgg16 (Model)                multiple                  14714688
_________________________________________________________________
flatten (Flatten)            (None, 8192)              0
_________________________________________________________________
fc2 (Dense)                  (None, 1024)              8389632
_________________________________________________________________
dropout_1 (Dropout)          (None, 1024)              0
_________________________________________________________________
dense_1 (Dense)              (None, 100)               102500
=================================================================
Total params: 23,206,820
Trainable params: 23,206,820
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
125/125 [==============================] - 69s - loss: 4.5885 - categorical_accuracy: 0.0128 - val_loss: 4.4617 - val_categorical_accuracy: 0.0192
Epoch 2/50
125/125 [==============================] - 71s - loss: 4.4705 - categorical_accuracy: 0.0216 - val_loss: 4.3465 - val_categorical_accuracy: 0.0230
Epoch 3/50
125/125 [==============================] - 68s - loss: 4.2987 - categorical_accuracy: 0.0280 - val_loss: 4.1375 - val_categorical_accuracy: 0.0418
Epoch 4/50
125/125 [==============================] - 65s - loss: 4.2431 - categorical_accuracy: 0.0315 - val_loss: 4.0817 - val_categorical_accuracy: 0.0429
Epoch 5/50
125/125 [==============================] - 63s - loss: 4.0659 - categorical_accuracy: 0.0489 - val_loss: 4.0029 - val_categorical_accuracy: 0.0641
Epoch 6/50
125/125 [==============================] - 62s - loss: 3.8058 - categorical_accuracy: 0.0776 - val_loss: 3.6158 - val_categorical_accuracy: 0.1011
Epoch 7/50
125/125 [==============================] - 67s - loss: 3.5679 - categorical_accuracy: 0.1098 - val_loss: 3.3856 - val_categorical_accuracy: 0.1447
Epoch 8/50
125/125 [==============================] - 64s - loss: 3.2790 - categorical_accuracy: 0.1533 - val_loss: 3.1765 - val_categorical_accuracy: 0.1772
Epoch 9/50
125/125 [==============================] - 66s - loss: 3.1514 - categorical_accuracy: 0.1807 - val_loss: 2.9329 - val_categorical_accuracy: 0.2202
Epoch 10/50
125/125 [==============================] - 64s - loss: 2.8442 - categorical_accuracy: 0.2390 - val_loss: 2.6621 - val_categorical_accuracy: 0.2740
Epoch 11/50
125/125 [==============================] - 62s - loss: 2.6454 - categorical_accuracy: 0.2805 - val_loss: 2.4664 - val_categorical_accuracy: 0.3086
Epoch 12/50
125/125 [==============================] - 64s - loss: 2.3941 - categorical_accuracy: 0.3329 - val_loss: 2.3747 - val_categorical_accuracy: 0.3563
Epoch 13/50
125/125 [==============================] - 65s - loss: 2.2797 - categorical_accuracy: 0.3563 - val_loss: 2.1719 - val_categorical_accuracy: 0.3884
Epoch 14/50
125/125 [==============================] - 66s - loss: 2.1125 - categorical_accuracy: 0.3933 - val_loss: 2.2312 - val_categorical_accuracy: 0.3978
Epoch 15/50
125/125 [==============================] - 63s - loss: 1.9840 - categorical_accuracy: 0.4269 - val_loss: 2.1964 - val_categorical_accuracy: 0.3982
Epoch 16/50
125/125 [==============================] - 64s - loss: 1.8985 - categorical_accuracy: 0.4460 - val_loss: 2.3000 - val_categorical_accuracy: 0.3733
Epoch 17/50
125/125 [==============================] - 66s - loss: 1.7567 - categorical_accuracy: 0.4817 - val_loss: 2.1729 - val_categorical_accuracy: 0.3902
Epoch 18/50
125/125 [==============================] - 69s - loss: 1.6542 - categorical_accuracy: 0.5103 - val_loss: 2.0268 - val_categorical_accuracy: 0.4250
Epoch 19/50
125/125 [==============================] - 64s - loss: 1.5689 - categorical_accuracy: 0.5250 - val_loss: 1.9292 - val_categorical_accuracy: 0.4563
Epoch 20/50
125/125 [==============================] - 69s - loss: 1.4613 - categorical_accuracy: 0.5596 - val_loss: 2.0235 - val_categorical_accuracy: 0.4470
Epoch 21/50
125/125 [==============================] - 64s - loss: 1.3929 - categorical_accuracy: 0.5779 - val_loss: 2.1750 - val_categorical_accuracy: 0.4245
Epoch 22/50
125/125 [==============================] - 64s - loss: 1.3215 - categorical_accuracy: 0.5933 - val_loss: 1.9367 - val_categorical_accuracy: 0.4649
Epoch 23/50
125/125 [==============================] - 64s - loss: 1.2547 - categorical_accuracy: 0.6109 - val_loss: 2.0026 - val_categorical_accuracy: 0.4699
Epoch 24/50
125/125 [==============================] - 63s - loss: 1.1573 - categorical_accuracy: 0.6356 - val_loss: 1.9361 - val_categorical_accuracy: 0.4805
Epoch 25/50
125/125 [==============================] - 67s - loss: 1.0839 - categorical_accuracy: 0.6589 - val_loss: 2.1948 - val_categorical_accuracy: 0.4404
Epoch 26/50
125/125 [==============================] - 62s - loss: 1.0735 - categorical_accuracy: 0.6624 - val_loss: 1.9492 - val_categorical_accuracy: 0.4836
Epoch 27/50
125/125 [==============================] - 65s - loss: 0.9931 - categorical_accuracy: 0.6827 - val_loss: 2.0051 - val_categorical_accuracy: 0.4780
Epoch 28/50
125/125 [==============================] - 63s - loss: 0.9786 - categorical_accuracy: 0.6921 - val_loss: 2.1009 - val_categorical_accuracy: 0.4765
Epoch 29/50
125/125 [==============================] - 71s - loss: 0.8887 - categorical_accuracy: 0.7131 - val_loss: 1.9851 - val_categorical_accuracy: 0.5070
Epoch 30/50
125/125 [==============================] - 69s - loss: 0.8207 - categorical_accuracy: 0.7390 - val_loss: 2.0744 - val_categorical_accuracy: 0.4922
Epoch 31/50
125/125 [==============================] - 63s - loss: 0.8261 - categorical_accuracy: 0.7364 - val_loss: 2.0414 - val_categorical_accuracy: 0.5045
Epoch 32/50
125/125 [==============================] - 65s - loss: 0.7379 - categorical_accuracy: 0.7599 - val_loss: 2.4413 - val_categorical_accuracy: 0.4441
Epoch 33/50
125/125 [==============================] - 69s - loss: 0.7222 - categorical_accuracy: 0.7654 - val_loss: 2.1884 - val_categorical_accuracy: 0.4818
Epoch 34/50
125/125 [==============================] - 64s - loss: 0.6796 - categorical_accuracy: 0.7810 - val_loss: 2.2197 - val_categorical_accuracy: 0.4876
Epoch 35/50
125/125 [==============================] - 59s - loss: 0.6464 - categorical_accuracy: 0.7930 - val_loss: 2.1181 - val_categorical_accuracy: 0.4943
Epoch 36/50
125/125 [==============================] - 68s - loss: 0.6207 - categorical_accuracy: 0.7941 - val_loss: 2.1807 - val_categorical_accuracy: 0.5146
Epoch 37/50
125/125 [==============================] - 69s - loss: 0.5835 - categorical_accuracy: 0.8126 - val_loss: 1.9763 - val_categorical_accuracy: 0.5200
Epoch 38/50
125/125 [==============================] - 69s - loss: 0.6034 - categorical_accuracy: 0.8074 - val_loss: 2.1559 - val_categorical_accuracy: 0.5003
Epoch 39/50
125/125 [==============================] - 68s - loss: 0.5750 - categorical_accuracy: 0.8138 - val_loss: 2.1164 - val_categorical_accuracy: 0.5152
Epoch 40/50
125/125 [==============================] - 64s - loss: 0.5296 - categorical_accuracy: 0.8220 - val_loss: 2.3888 - val_categorical_accuracy: 0.4841
Epoch 41/50
125/125 [==============================] - 64s - loss: 0.5226 - categorical_accuracy: 0.8243 - val_loss: 2.2011 - val_categorical_accuracy: 0.5215
Epoch 42/50
125/125 [==============================] - 65s - loss: 0.4871 - categorical_accuracy: 0.8381 - val_loss: 2.4010 - val_categorical_accuracy: 0.4899
Epoch 43/50
125/125 [==============================] - 65s - loss: 0.4513 - categorical_accuracy: 0.8561 - val_loss: 2.2898 - val_categorical_accuracy: 0.4992
Epoch 44/50
125/125 [==============================] - 67s - loss: 0.4431 - categorical_accuracy: 0.8580 - val_loss: 2.4058 - val_categorical_accuracy: 0.5071
Epoch 45/50
125/125 [==============================] - 67s - loss: 0.3997 - categorical_accuracy: 0.8691 - val_loss: 2.4084 - val_categorical_accuracy: 0.4991
Epoch 46/50
125/125 [==============================] - 68s - loss: 0.4096 - categorical_accuracy: 0.8612 - val_loss: 2.5210 - val_categorical_accuracy: 0.4992
Epoch 47/50
125/125 [==============================] - 63s - loss: 0.4002 - categorical_accuracy: 0.8695 - val_loss: 2.5062 - val_categorical_accuracy: 0.4924
Epoch 48/50
125/125 [==============================] - 65s - loss: 0.3420 - categorical_accuracy: 0.8847 - val_loss: 2.4797 - val_categorical_accuracy: 0.5080
Epoch 49/50
125/125 [==============================] - 66s - loss: 0.3605 - categorical_accuracy: 0.8811 - val_loss: 2.3985 - val_categorical_accuracy: 0.5106
Epoch 50/50
125/125 [==============================] - 66s - loss: 0.4012 - categorical_accuracy: 0.8692 - val_loss: 2.7448 - val_categorical_accuracy: 0.4711
----------------------
class labels are: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '57', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '94', '95', '97', '101', '109', '111', '114', '115', '120', '123', '126', '127', '128', '129', '132', '133']
Found 8153 images belonging to 100 classes.
{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14, '16': 15, '17': 16, '18': 17, '19': 18, '20': 19, '21': 20, '22': 21, '23': 22, '24': 23, '25': 24, '26': 25, '27': 26, '28': 27, '29': 28, '30': 29, '31': 30, '32': 31, '33': 32, '34': 33, '35': 34, '36': 35, '37': 36, '38': 37, '39': 38, '40': 39, '41': 40, '42': 41, '43': 42, '45': 43, '46': 44, '47': 45, '48': 46, '49': 47, '50': 48, '51': 49, '52': 50, '53': 51, '54': 52, '57': 53, '59': 54, '60': 55, '61': 56, '62': 57, '63': 58, '64': 59, '65': 60, '66': 61, '67': 62, '68': 63, '69': 64, '70': 65, '71': 66, '72': 67, '73': 68, '74': 69, '75': 70, '76': 71, '77': 72, '78': 73, '79': 74, '80': 75, '81': 76, '82': 77, '83': 78, '84': 79, '85': 80, '86': 81, '87': 82, '88': 83, '94': 84, '95': 85, '97': 86, '101': 87, '109': 88, '111': 89, '114': 90, '115': 91, '120': 92, '123': 93, '126': 94, '127': 95, '128': 96, '129': 97, '132': 98, '133': 99}
Found 10551 images belonging to 100 classes.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_2 (InputLayer)         (None, None, None, 3)     0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, None, None, 64)    1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, None, None, 64)    36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, None, None, 64)    0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, None, None, 128)   73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, None, None, 128)   147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, None, None, 128)   0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, None, None, 256)   295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, None, None, 256)   0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, None, None, 512)   1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, None, None, 512)   0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, None, None, 512)   0
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
image_input (InputLayer)     (None, 128, 128, 3)       0
_________________________________________________________________
vgg16 (Model)                multiple                  14714688
_________________________________________________________________
flatten (Flatten)            (None, 8192)              0
_________________________________________________________________
fc2 (Dense)                  (None, 1024)              8389632
_________________________________________________________________
dropout_2 (Dropout)          (None, 1024)              0
_________________________________________________________________
dense_2 (Dense)              (None, 100)               102500
=================================================================
Total params: 23,206,820
Trainable params: 23,206,820
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
125/125 [==============================] - 76s - loss: 4.6118 - categorical_accuracy: 0.0112 - val_loss: 4.5842 - val_categorical_accuracy: 0.0172
Epoch 2/50
125/125 [==============================] - 66s - loss: 4.5800 - categorical_accuracy: 0.0116 - val_loss: 4.5642 - val_categorical_accuracy: 0.0126
Epoch 3/50
125/125 [==============================] - 62s - loss: 4.5687 - categorical_accuracy: 0.0087 - val_loss: 4.5474 - val_categorical_accuracy: 0.0099
Epoch 4/50
125/125 [==============================] - 66s - loss: 4.5595 - categorical_accuracy: 0.0096 - val_loss: 4.5299 - val_categorical_accuracy: 0.0131
Epoch 5/50
125/125 [==============================] - 62s - loss: 4.5547 - categorical_accuracy: 0.0109 - val_loss: 4.5314 - val_categorical_accuracy: 0.0141
Epoch 6/50
125/125 [==============================] - 63s - loss: 4.5527 - categorical_accuracy: 0.0127 - val_loss: 4.5250 - val_categorical_accuracy: 0.0094
Epoch 7/50
125/125 [==============================] - 66s - loss: 4.5466 - categorical_accuracy: 0.0117 - val_loss: 4.5221 - val_categorical_accuracy: 0.0124
Epoch 8/50
125/125 [==============================] - 70s - loss: 4.5518 - categorical_accuracy: 0.0099 - val_loss: 4.5229 - val_categorical_accuracy: 0.0199
Epoch 9/50
125/125 [==============================] - 61s - loss: 4.5481 - categorical_accuracy: 0.0099 - val_loss: 4.5222 - val_categorical_accuracy: 0.0136
Epoch 10/50
125/125 [==============================] - 66s - loss: 4.5485 - categorical_accuracy: 0.0118 - val_loss: 4.5130 - val_categorical_accuracy: 0.0134
Epoch 11/50
125/125 [==============================] - 71s - loss: 4.5495 - categorical_accuracy: 0.0128 - val_loss: 4.5183 - val_categorical_accuracy: 0.0138
Epoch 12/50
125/125 [==============================] - 65s - loss: 4.5458 - categorical_accuracy: 0.0119 - val_loss: 4.5149 - val_categorical_accuracy: 0.0091
Epoch 13/50
125/125 [==============================] - 65s - loss: 4.5489 - categorical_accuracy: 0.0144 - val_loss: 4.5206 - val_categorical_accuracy: 0.0096
Epoch 14/50
125/125 [==============================] - 67s - loss: 4.5462 - categorical_accuracy: 0.0106 - val_loss: 4.5190 - val_categorical_accuracy: 0.0109
Epoch 15/50
125/125 [==============================] - 62s - loss: 4.5510 - categorical_accuracy: 0.0099 - val_loss: 4.5171 - val_categorical_accuracy: 0.0068
Epoch 16/50
125/125 [==============================] - 63s - loss: 4.5485 - categorical_accuracy: 0.0111 - val_loss: 4.5195 - val_categorical_accuracy: 0.0125
Epoch 17/50
125/125 [==============================] - 66s - loss: 4.5465 - categorical_accuracy: 0.0103 - val_loss: 4.5138 - val_categorical_accuracy: 0.0093
Epoch 18/50
125/125 [==============================] - 68s - loss: 4.5470 - categorical_accuracy: 0.0109 - val_loss: 4.5233 - val_categorical_accuracy: 0.0098
Epoch 19/50
125/125 [==============================] - 66s - loss: 4.5490 - categorical_accuracy: 0.0112 - val_loss: 4.5206 - val_categorical_accuracy: 0.0102
Epoch 20/50
125/125 [==============================] - 66s - loss: 4.5466 - categorical_accuracy: 0.0102 - val_loss: 4.5199 - val_categorical_accuracy: 0.0154
Epoch 21/50
125/125 [==============================] - 69s - loss: 4.5482 - categorical_accuracy: 0.0110 - val_loss: 4.5151 - val_categorical_accuracy: 0.0169
Epoch 22/50
125/125 [==============================] - 64s - loss: 4.5465 - categorical_accuracy: 0.0090 - val_loss: 4.5182 - val_categorical_accuracy: 0.0106
Epoch 23/50
125/125 [==============================] - 66s - loss: 4.5499 - categorical_accuracy: 0.0123 - val_loss: 4.5166 - val_categorical_accuracy: 0.0144
Epoch 24/50
125/125 [==============================] - 64s - loss: 4.5444 - categorical_accuracy: 0.0102 - val_loss: 4.5158 - val_categorical_accuracy: 0.0148
Epoch 25/50
125/125 [==============================] - 64s - loss: 4.5485 - categorical_accuracy: 0.0110 - val_loss: 4.5187 - val_categorical_accuracy: 0.0131
Epoch 26/50
125/125 [==============================] - 66s - loss: 4.5495 - categorical_accuracy: 0.0109 - val_loss: 4.5184 - val_categorical_accuracy: 0.0124
Epoch 27/50
125/125 [==============================] - 64s - loss: 4.5442 - categorical_accuracy: 0.0111 - val_loss: 4.5276 - val_categorical_accuracy: 0.0102
Epoch 28/50
125/125 [==============================] - 63s - loss: 4.5462 - categorical_accuracy: 0.0109 - val_loss: 4.5113 - val_categorical_accuracy: 0.0119
Epoch 29/50
125/125 [==============================] - 64s - loss: 4.5476 - categorical_accuracy: 0.0099 - val_loss: 4.5215 - val_categorical_accuracy: 0.0143
Epoch 30/50
125/125 [==============================] - 61s - loss: 4.5479 - categorical_accuracy: 0.0104 - val_loss: 4.5251 - val_categorical_accuracy: 0.0119
Epoch 31/50
125/125 [==============================] - 66s - loss: 4.5477 - categorical_accuracy: 0.0116 - val_loss: 4.5094 - val_categorical_accuracy: 0.0086
Epoch 32/50
125/125 [==============================] - 69s - loss: 4.5468 - categorical_accuracy: 0.0118 - val_loss: 4.5217 - val_categorical_accuracy: 0.0102
Epoch 33/50
125/125 [==============================] - 67s - loss: 4.5498 - categorical_accuracy: 0.0100 - val_loss: 4.5119 - val_categorical_accuracy: 0.0139
Epoch 34/50
125/125 [==============================] - 66s - loss: 4.5450 - categorical_accuracy: 0.0111 - val_loss: 4.5217 - val_categorical_accuracy: 0.0073
Epoch 35/50
125/125 [==============================] - 68s - loss: 4.5437 - categorical_accuracy: 0.0128 - val_loss: 4.5160 - val_categorical_accuracy: 0.0115
Epoch 36/50
125/125 [==============================] - 64s - loss: 4.5487 - categorical_accuracy: 0.0116 - val_loss: 4.5216 - val_categorical_accuracy: 0.0091
Epoch 37/50
125/125 [==============================] - 68s - loss: 4.5470 - categorical_accuracy: 0.0109 - val_loss: 4.5135 - val_categorical_accuracy: 0.0120
Epoch 38/50
125/125 [==============================] - 69s - loss: 4.5486 - categorical_accuracy: 0.0102 - val_loss: 4.5192 - val_categorical_accuracy: 0.0144
Epoch 39/50
125/125 [==============================] - 64s - loss: 4.5488 - categorical_accuracy: 0.0110 - val_loss: 4.5163 - val_categorical_accuracy: 0.0139
Epoch 40/50
125/125 [==============================] - 63s - loss: 4.5450 - categorical_accuracy: 0.0107 - val_loss: 4.5247 - val_categorical_accuracy: 0.0120
Epoch 41/50
125/125 [==============================] - 62s - loss: 4.5482 - categorical_accuracy: 0.0104 - val_loss: 4.5225 - val_categorical_accuracy: 0.0157
Epoch 42/50
125/125 [==============================] - 64s - loss: 4.5471 - categorical_accuracy: 0.0109 - val_loss: 4.5096 - val_categorical_accuracy: 0.0104
Epoch 43/50
125/125 [==============================] - 62s - loss: 4.5468 - categorical_accuracy: 0.0102 - val_loss: 4.5231 - val_categorical_accuracy: 0.0141
Epoch 44/50
125/125 [==============================] - 64s - loss: 4.5479 - categorical_accuracy: 0.0112 - val_loss: 4.5146 - val_categorical_accuracy: 0.0172
Epoch 45/50
125/125 [==============================] - 64s - loss: 4.5466 - categorical_accuracy: 0.0100 - val_loss: 4.5160 - val_categorical_accuracy: 0.0150
Epoch 46/50
125/125 [==============================] - 67s - loss: 4.5457 - categorical_accuracy: 0.0113 - val_loss: 4.5234 - val_categorical_accuracy: 0.0109
Epoch 47/50
125/125 [==============================] - 64s - loss: 4.5482 - categorical_accuracy: 0.0113 - val_loss: 4.5130 - val_categorical_accuracy: 0.0139
Epoch 48/50
125/125 [==============================] - 66s - loss: 4.5428 - categorical_accuracy: 0.0106 - val_loss: 4.5187 - val_categorical_accuracy: 0.0148
Epoch 49/50
125/125 [==============================] - 67s - loss: 4.5452 - categorical_accuracy: 0.0131 - val_loss: 4.5187 - val_categorical_accuracy: 0.0116
Epoch 50/50
125/125 [==============================] - 66s - loss: 4.5471 - categorical_accuracy: 0.0118 - val_loss: 4.5154 - val_categorical_accuracy: 0.0122
----------------------
class labels are: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '57', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '94', '95', '97', '101', '109', '111', '114', '115', '120', '123', '126', '127', '128', '129', '132', '133']
Found 8153 images belonging to 100 classes.
{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14, '16': 15, '17': 16, '18': 17, '19': 18, '20': 19, '21': 20, '22': 21, '23': 22, '24': 23, '25': 24, '26': 25, '27': 26, '28': 27, '29': 28, '30': 29, '31': 30, '32': 31, '33': 32, '34': 33, '35': 34, '36': 35, '37': 36, '38': 37, '39': 38, '40': 39, '41': 40, '42': 41, '43': 42, '45': 43, '46': 44, '47': 45, '48': 46, '49': 47, '50': 48, '51': 49, '52': 50, '53': 51, '54': 52, '57': 53, '59': 54, '60': 55, '61': 56, '62': 57, '63': 58, '64': 59, '65': 60, '66': 61, '67': 62, '68': 63, '69': 64, '70': 65, '71': 66, '72': 67, '73': 68, '74': 69, '75': 70, '76': 71, '77': 72, '78': 73, '79': 74, '80': 75, '81': 76, '82': 77, '83': 78, '84': 79, '85': 80, '86': 81, '87': 82, '88': 83, '94': 84, '95': 85, '97': 86, '101': 87, '109': 88, '111': 89, '114': 90, '115': 91, '120': 92, '123': 93, '126': 94, '127': 95, '128': 96, '129': 97, '132': 98, '133': 99}
Found 10551 images belonging to 100 classes.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_3 (InputLayer)         (None, None, None, 3)     0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, None, None, 64)    1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, None, None, 64)    36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, None, None, 64)    0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, None, None, 128)   73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, None, None, 128)   147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, None, None, 128)   0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, None, None, 256)   295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, None, None, 256)   0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, None, None, 512)   1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, None, None, 512)   0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, None, None, 512)   0
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
image_input (InputLayer)     (None, 128, 128, 3)       0
_________________________________________________________________
vgg16 (Model)                multiple                  14714688
_________________________________________________________________
flatten (Flatten)            (None, 8192)              0
_________________________________________________________________
fc2 (Dense)                  (None, 1024)              8389632
_________________________________________________________________
dropout_3 (Dropout)          (None, 1024)              0
_________________________________________________________________
dense_3 (Dense)              (None, 100)               102500
=================================================================
Total params: 23,206,820
Trainable params: 23,206,820
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
125/125 [==============================] - 68s - loss: 4.7686 - categorical_accuracy: 0.0090 - val_loss: 4.5865 - val_categorical_accuracy: 0.0131
Epoch 2/50
125/125 [==============================] - 66s - loss: 4.5828 - categorical_accuracy: 0.0112 - val_loss: 4.5676 - val_categorical_accuracy: 0.0131
Epoch 3/50
125/125 [==============================] - 65s - loss: 4.5711 - categorical_accuracy: 0.0093 - val_loss: 4.5516 - val_categorical_accuracy: 0.0145
Epoch 4/50
125/125 [==============================] - 69s - loss: 4.5630 - categorical_accuracy: 0.0113 - val_loss: 4.5419 - val_categorical_accuracy: 0.0129
Epoch 5/50
125/125 [==============================] - 64s - loss: 4.5561 - categorical_accuracy: 0.0106 - val_loss: 4.5340 - val_categorical_accuracy: 0.0126
Epoch 6/50
125/125 [==============================] - 65s - loss: 4.5500 - categorical_accuracy: 0.0123 - val_loss: 4.5216 - val_categorical_accuracy: 0.0145
Epoch 7/50
125/125 [==============================] - 64s - loss: 4.5517 - categorical_accuracy: 0.0105 - val_loss: 4.5286 - val_categorical_accuracy: 0.0134
Epoch 8/50
125/125 [==============================] - 68s - loss: 4.5496 - categorical_accuracy: 0.0113 - val_loss: 4.5238 - val_categorical_accuracy: 0.0171
Epoch 9/50
125/125 [==============================] - 65s - loss: 4.5474 - categorical_accuracy: 0.0126 - val_loss: 4.5160 - val_categorical_accuracy: 0.0129
Epoch 10/50
125/125 [==============================] - 67s - loss: 4.5482 - categorical_accuracy: 0.0104 - val_loss: 4.5219 - val_categorical_accuracy: 0.0162
Epoch 11/50
125/125 [==============================] - 62s - loss: 4.5467 - categorical_accuracy: 0.0118 - val_loss: 4.5191 - val_categorical_accuracy: 0.0140
Epoch 12/50
125/125 [==============================] - 65s - loss: 4.5491 - categorical_accuracy: 0.0118 - val_loss: 4.5155 - val_categorical_accuracy: 0.0114
Epoch 13/50
125/125 [==============================] - 65s - loss: 4.5464 - categorical_accuracy: 0.0109 - val_loss: 4.5199 - val_categorical_accuracy: 0.0149
Epoch 14/50
125/125 [==============================] - 63s - loss: 4.5476 - categorical_accuracy: 0.0138 - val_loss: 4.5132 - val_categorical_accuracy: 0.0178
Epoch 15/50
125/125 [==============================] - 64s - loss: 4.5489 - categorical_accuracy: 0.0126 - val_loss: 4.5198 - val_categorical_accuracy: 0.0078
Epoch 16/50
125/125 [==============================] - 65s - loss: 4.5465 - categorical_accuracy: 0.0107 - val_loss: 4.5208 - val_categorical_accuracy: 0.0145
Epoch 17/50
125/125 [==============================] - 62s - loss: 4.5460 - categorical_accuracy: 0.0120 - val_loss: 4.5206 - val_categorical_accuracy: 0.0106
Epoch 18/50
125/125 [==============================] - 62s - loss: 4.5522 - categorical_accuracy: 0.0096 - val_loss: 4.5111 - val_categorical_accuracy: 0.0149
Epoch 19/50
125/125 [==============================] - 63s - loss: 4.5458 - categorical_accuracy: 0.0117 - val_loss: 4.5208 - val_categorical_accuracy: 0.0130
Epoch 20/50
125/125 [==============================] - 64s - loss: 4.5484 - categorical_accuracy: 0.0102 - val_loss: 4.5217 - val_categorical_accuracy: 0.0146
Epoch 21/50
125/125 [==============================] - 62s - loss: 4.5455 - categorical_accuracy: 0.0116 - val_loss: 4.5171 - val_categorical_accuracy: 0.0172
Epoch 22/50
125/125 [==============================] - 65s - loss: 4.5458 - categorical_accuracy: 0.0116 - val_loss: 4.5169 - val_categorical_accuracy: 0.0109
Epoch 23/50
125/125 [==============================] - 65s - loss: 4.5472 - categorical_accuracy: 0.0143 - val_loss: 4.5127 - val_categorical_accuracy: 0.0144
Epoch 24/50
125/125 [==============================] - 65s - loss: 4.5460 - categorical_accuracy: 0.0117 - val_loss: 4.5210 - val_categorical_accuracy: 0.0138
Epoch 25/50
125/125 [==============================] - 61s - loss: 4.5516 - categorical_accuracy: 0.0117 - val_loss: 4.5220 - val_categorical_accuracy: 0.0131
Epoch 26/50
125/125 [==============================] - 65s - loss: 4.5427 - categorical_accuracy: 0.0111 - val_loss: 4.5112 - val_categorical_accuracy: 0.0126
Epoch 27/50
125/125 [==============================] - 63s - loss: 4.5490 - categorical_accuracy: 0.0121 - val_loss: 4.5224 - val_categorical_accuracy: 0.0115
Epoch 28/50
125/125 [==============================] - 65s - loss: 4.5459 - categorical_accuracy: 0.0108 - val_loss: 4.5172 - val_categorical_accuracy: 0.0134
Epoch 29/50
125/125 [==============================] - 62s - loss: 4.5480 - categorical_accuracy: 0.0119 - val_loss: 4.5137 - val_categorical_accuracy: 0.0140
Epoch 30/50
125/125 [==============================] - 65s - loss: 4.5452 - categorical_accuracy: 0.0126 - val_loss: 4.5184 - val_categorical_accuracy: 0.0149
Epoch 31/50
125/125 [==============================] - 62s - loss: 4.5480 - categorical_accuracy: 0.0114 - val_loss: 4.5198 - val_categorical_accuracy: 0.0093
Epoch 32/50
125/125 [==============================] - 63s - loss: 4.5463 - categorical_accuracy: 0.0105 - val_loss: 4.5210 - val_categorical_accuracy: 0.0132
Epoch 33/50
125/125 [==============================] - 63s - loss: 4.5460 - categorical_accuracy: 0.0124 - val_loss: 4.5196 - val_categorical_accuracy: 0.0146
Epoch 34/50
125/125 [==============================] - 65s - loss: 4.5465 - categorical_accuracy: 0.0110 - val_loss: 4.5152 - val_categorical_accuracy: 0.0146
Epoch 35/50
125/125 [==============================] - 64s - loss: 4.5447 - categorical_accuracy: 0.0126 - val_loss: 4.5101 - val_categorical_accuracy: 0.0143
Epoch 36/50
125/125 [==============================] - 62s - loss: 4.5509 - categorical_accuracy: 0.0119 - val_loss: 4.5205 - val_categorical_accuracy: 0.0109
Epoch 37/50
125/125 [==============================] - 62s - loss: 4.5423 - categorical_accuracy: 0.0104 - val_loss: 4.5192 - val_categorical_accuracy: 0.0153
Epoch 38/50
125/125 [==============================] - 62s - loss: 4.5474 - categorical_accuracy: 0.0119 - val_loss: 4.5280 - val_categorical_accuracy: 0.0162
Epoch 39/50
125/125 [==============================] - 65s - loss: 4.5463 - categorical_accuracy: 0.0121 - val_loss: 4.5114 - val_categorical_accuracy: 0.0121
Epoch 40/50
125/125 [==============================] - 64s - loss: 4.5453 - categorical_accuracy: 0.0107 - val_loss: 4.5115 - val_categorical_accuracy: 0.0143
Epoch 41/50
125/125 [==============================] - 63s - loss: 4.5483 - categorical_accuracy: 0.0110 - val_loss: 4.5193 - val_categorical_accuracy: 0.0098
Epoch 42/50
125/125 [==============================] - 62s - loss: 4.5472 - categorical_accuracy: 0.0108 - val_loss: 4.5211 - val_categorical_accuracy: 0.0167
Epoch 43/50
125/125 [==============================] - 65s - loss: 4.5453 - categorical_accuracy: 0.0110 - val_loss: 4.5176 - val_categorical_accuracy: 0.0174
Epoch 44/50
125/125 [==============================] - 69s - loss: 4.5448 - categorical_accuracy: 0.0090 - val_loss: 4.5170 - val_categorical_accuracy: 0.0144
Epoch 45/50
125/125 [==============================] - 65s - loss: 4.5492 - categorical_accuracy: 0.0118 - val_loss: 4.5171 - val_categorical_accuracy: 0.0153
Epoch 46/50
125/125 [==============================] - 63s - loss: 4.5468 - categorical_accuracy: 0.0116 - val_loss: 4.5236 - val_categorical_accuracy: 0.0157
Epoch 47/50
125/125 [==============================] - 65s - loss: 4.5442 - categorical_accuracy: 0.0111 - val_loss: 4.5122 - val_categorical_accuracy: 0.0129
Epoch 48/50
125/125 [==============================] - 63s - loss: 4.5487 - categorical_accuracy: 0.0110 - val_loss: 4.5216 - val_categorical_accuracy: 0.0163
Epoch 49/50
125/125 [==============================] - 62s - loss: 4.5449 - categorical_accuracy: 0.0107 - val_loss: 4.5134 - val_categorical_accuracy: 0.0217
Epoch 50/50
125/125 [==============================] - 66s - loss: 4.5456 - categorical_accuracy: 0.0117 - val_loss: 4.5165 - val_categorical_accuracy: 0.0173
----------------------
class labels are: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '57', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '94', '95', '97', '101', '109', '111', '114', '115', '120', '123', '126', '127', '128', '129', '132', '133']
Found 8153 images belonging to 100 classes.
{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14, '16': 15, '17': 16, '18': 17, '19': 18, '20': 19, '21': 20, '22': 21, '23': 22, '24': 23, '25': 24, '26': 25, '27': 26, '28': 27, '29': 28, '30': 29, '31': 30, '32': 31, '33': 32, '34': 33, '35': 34, '36': 35, '37': 36, '38': 37, '39': 38, '40': 39, '41': 40, '42': 41, '43': 42, '45': 43, '46': 44, '47': 45, '48': 46, '49': 47, '50': 48, '51': 49, '52': 50, '53': 51, '54': 52, '57': 53, '59': 54, '60': 55, '61': 56, '62': 57, '63': 58, '64': 59, '65': 60, '66': 61, '67': 62, '68': 63, '69': 64, '70': 65, '71': 66, '72': 67, '73': 68, '74': 69, '75': 70, '76': 71, '77': 72, '78': 73, '79': 74, '80': 75, '81': 76, '82': 77, '83': 78, '84': 79, '85': 80, '86': 81, '87': 82, '88': 83, '94': 84, '95': 85, '97': 86, '101': 87, '109': 88, '111': 89, '114': 90, '115': 91, '120': 92, '123': 93, '126': 94, '127': 95, '128': 96, '129': 97, '132': 98, '133': 99}
Found 10551 images belonging to 100 classes.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_4 (InputLayer)         (None, None, None, 3)     0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, None, None, 64)    1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, None, None, 64)    36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, None, None, 64)    0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, None, None, 128)   73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, None, None, 128)   147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, None, None, 128)   0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, None, None, 256)   295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, None, None, 256)   0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, None, None, 512)   1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, None, None, 512)   0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, None, None, 512)   0
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
image_input (InputLayer)     (None, 128, 128, 3)       0
_________________________________________________________________
vgg16 (Model)                multiple                  14714688
_________________________________________________________________
flatten (Flatten)            (None, 8192)              0
_________________________________________________________________
fc2 (Dense)                  (None, 1024)              8389632
_________________________________________________________________
dropout_4 (Dropout)          (None, 1024)              0
_________________________________________________________________
dense_4 (Dense)              (None, 100)               102500
=================================================================
Total params: 23,206,820
Trainable params: 23,206,820
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
125/125 [==============================] - 71s - loss: 4.6054 - categorical_accuracy: 0.0091 - val_loss: 4.5836 - val_categorical_accuracy: 0.0149
Epoch 2/50
125/125 [==============================] - 67s - loss: 4.5642 - categorical_accuracy: 0.0132 - val_loss: 4.5251 - val_categorical_accuracy: 0.0152
Epoch 3/50
125/125 [==============================] - 68s - loss: 4.4854 - categorical_accuracy: 0.0159 - val_loss: 4.3752 - val_categorical_accuracy: 0.0214
Epoch 4/50
125/125 [==============================] - 70s - loss: 4.3385 - categorical_accuracy: 0.0269 - val_loss: 4.1791 - val_categorical_accuracy: 0.0316
Epoch 5/50
125/125 [==============================] - 69s - loss: 4.1749 - categorical_accuracy: 0.0382 - val_loss: 4.0234 - val_categorical_accuracy: 0.0467
Epoch 6/50
125/125 [==============================] - 66s - loss: 3.9809 - categorical_accuracy: 0.0590 - val_loss: 3.7731 - val_categorical_accuracy: 0.0812
Epoch 7/50
125/125 [==============================] - 67s - loss: 3.7705 - categorical_accuracy: 0.0824 - val_loss: 3.5075 - val_categorical_accuracy: 0.1230
Epoch 8/50
125/125 [==============================] - 70s - loss: 3.5477 - categorical_accuracy: 0.1113 - val_loss: 3.3310 - val_categorical_accuracy: 0.1383
Epoch 9/50
125/125 [==============================] - 70s - loss: 3.2736 - categorical_accuracy: 0.1585 - val_loss: 2.9382 - val_categorical_accuracy: 0.2061
Epoch 10/50
125/125 [==============================] - 67s - loss: 3.0876 - categorical_accuracy: 0.1867 - val_loss: 2.7958 - val_categorical_accuracy: 0.2472
Epoch 11/50
125/125 [==============================] - 66s - loss: 2.7573 - categorical_accuracy: 0.2549 - val_loss: 2.6331 - val_categorical_accuracy: 0.2860
Epoch 12/50
125/125 [==============================] - 68s - loss: 2.6449 - categorical_accuracy: 0.2770 - val_loss: 2.5480 - val_categorical_accuracy: 0.3144
Epoch 13/50
125/125 [==============================] - 72s - loss: 2.5195 - categorical_accuracy: 0.3065 - val_loss: 2.5205 - val_categorical_accuracy: 0.3167
Epoch 14/50
125/125 [==============================] - 66s - loss: 2.3009 - categorical_accuracy: 0.3514 - val_loss: 2.4124 - val_categorical_accuracy: 0.3318
Epoch 15/50
125/125 [==============================] - 69s - loss: 2.1960 - categorical_accuracy: 0.3819 - val_loss: 2.2780 - val_categorical_accuracy: 0.3760
Epoch 16/50
125/125 [==============================] - 63s - loss: 2.0149 - categorical_accuracy: 0.4275 - val_loss: 2.2222 - val_categorical_accuracy: 0.3909
Epoch 17/50
125/125 [==============================] - 61s - loss: 1.8649 - categorical_accuracy: 0.4543 - val_loss: 2.1040 - val_categorical_accuracy: 0.4134
Epoch 18/50
125/125 [==============================] - 66s - loss: 1.8607 - categorical_accuracy: 0.4581 - val_loss: 2.2026 - val_categorical_accuracy: 0.4038
Epoch 19/50
125/125 [==============================] - 69s - loss: 1.7183 - categorical_accuracy: 0.4962 - val_loss: 2.0372 - val_categorical_accuracy: 0.4421
Epoch 20/50
125/125 [==============================] - 67s - loss: 1.6318 - categorical_accuracy: 0.5156 - val_loss: 2.2749 - val_categorical_accuracy: 0.3904
Epoch 21/50
125/125 [==============================] - 64s - loss: 1.5608 - categorical_accuracy: 0.5303 - val_loss: 2.0368 - val_categorical_accuracy: 0.4250
Epoch 22/50
125/125 [==============================] - 66s - loss: 1.4084 - categorical_accuracy: 0.5705 - val_loss: 1.9921 - val_categorical_accuracy: 0.4566
Epoch 23/50
125/125 [==============================] - 65s - loss: 1.3391 - categorical_accuracy: 0.5939 - val_loss: 2.2403 - val_categorical_accuracy: 0.4114
Epoch 24/50
125/125 [==============================] - 67s - loss: 1.2728 - categorical_accuracy: 0.6076 - val_loss: 2.0139 - val_categorical_accuracy: 0.4752
Epoch 25/50
125/125 [==============================] - 67s - loss: 1.1965 - categorical_accuracy: 0.6255 - val_loss: 1.9764 - val_categorical_accuracy: 0.4947
Epoch 26/50
125/125 [==============================] - 68s - loss: 1.1121 - categorical_accuracy: 0.6529 - val_loss: 2.1734 - val_categorical_accuracy: 0.4593
Epoch 27/50
125/125 [==============================] - 65s - loss: 1.1065 - categorical_accuracy: 0.6454 - val_loss: 2.0570 - val_categorical_accuracy: 0.4571
Epoch 28/50
125/125 [==============================] - 65s - loss: 1.0375 - categorical_accuracy: 0.6700 - val_loss: 2.0904 - val_categorical_accuracy: 0.4644
Epoch 29/50
125/125 [==============================] - 63s - loss: 0.9843 - categorical_accuracy: 0.6923 - val_loss: 1.9644 - val_categorical_accuracy: 0.4963
Epoch 30/50
125/125 [==============================] - 70s - loss: 0.9363 - categorical_accuracy: 0.7002 - val_loss: 1.9680 - val_categorical_accuracy: 0.4818
Epoch 31/50
125/125 [==============================] - 63s - loss: 0.8614 - categorical_accuracy: 0.7286 - val_loss: 1.9986 - val_categorical_accuracy: 0.5010
Epoch 32/50
125/125 [==============================] - 65s - loss: 0.8176 - categorical_accuracy: 0.7439 - val_loss: 2.2832 - val_categorical_accuracy: 0.4586
Epoch 33/50
125/125 [==============================] - 68s - loss: 0.7878 - categorical_accuracy: 0.7442 - val_loss: 2.1516 - val_categorical_accuracy: 0.4818
Epoch 34/50
125/125 [==============================] - 63s - loss: 0.7240 - categorical_accuracy: 0.7659 - val_loss: 2.2629 - val_categorical_accuracy: 0.4917
Epoch 35/50
125/125 [==============================] - 64s - loss: 0.7081 - categorical_accuracy: 0.7671 - val_loss: 2.1969 - val_categorical_accuracy: 0.4922
Epoch 36/50
125/125 [==============================] - 69s - loss: 0.6574 - categorical_accuracy: 0.7874 - val_loss: 2.3942 - val_categorical_accuracy: 0.4803
Epoch 37/50
125/125 [==============================] - 65s - loss: 0.6798 - categorical_accuracy: 0.7780 - val_loss: 2.3182 - val_categorical_accuracy: 0.4848
Epoch 38/50
125/125 [==============================] - 66s - loss: 0.6478 - categorical_accuracy: 0.7922 - val_loss: 2.4191 - val_categorical_accuracy: 0.4689
Epoch 39/50
125/125 [==============================] - 67s - loss: 0.5845 - categorical_accuracy: 0.8056 - val_loss: 2.3843 - val_categorical_accuracy: 0.4798
Epoch 40/50
125/125 [==============================] - 63s - loss: 0.5770 - categorical_accuracy: 0.8100 - val_loss: 2.2221 - val_categorical_accuracy: 0.4833
Epoch 41/50
125/125 [==============================] - 64s - loss: 0.5229 - categorical_accuracy: 0.8303 - val_loss: 2.1967 - val_categorical_accuracy: 0.4967
Epoch 42/50
125/125 [==============================] - 63s - loss: 0.5415 - categorical_accuracy: 0.8226 - val_loss: 2.3068 - val_categorical_accuracy: 0.4980
Epoch 43/50
125/125 [==============================] - 63s - loss: 0.4774 - categorical_accuracy: 0.8414 - val_loss: 2.5087 - val_categorical_accuracy: 0.4826
Epoch 44/50
125/125 [==============================] - 70s - loss: 0.4840 - categorical_accuracy: 0.8443 - val_loss: 2.4679 - val_categorical_accuracy: 0.4750
Epoch 45/50
125/125 [==============================] - 67s - loss: 0.5051 - categorical_accuracy: 0.8373 - val_loss: 2.3095 - val_categorical_accuracy: 0.4958
Epoch 46/50
125/125 [==============================] - 67s - loss: 0.4275 - categorical_accuracy: 0.8598 - val_loss: 2.4099 - val_categorical_accuracy: 0.4970
Epoch 47/50
125/125 [==============================] - 65s - loss: 0.4163 - categorical_accuracy: 0.8633 - val_loss: 2.3994 - val_categorical_accuracy: 0.5020
Epoch 48/50
125/125 [==============================] - 66s - loss: 0.4274 - categorical_accuracy: 0.8623 - val_loss: 2.4481 - val_categorical_accuracy: 0.4869
Epoch 49/50
125/125 [==============================] - 68s - loss: 0.4546 - categorical_accuracy: 0.8568 - val_loss: 2.5234 - val_categorical_accuracy: 0.5048
Epoch 50/50
125/125 [==============================] - 68s - loss: 0.3290 - categorical_accuracy: 0.8897 - val_loss: 2.4219 - val_categorical_accuracy: 0.5116
----------------------
class labels are: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '57', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '94', '95', '97', '101', '109', '111', '114', '115', '120', '123', '126', '127', '128', '129', '132', '133']
Found 8153 images belonging to 100 classes.
{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14, '16': 15, '17': 16, '18': 17, '19': 18, '20': 19, '21': 20, '22': 21, '23': 22, '24': 23, '25': 24, '26': 25, '27': 26, '28': 27, '29': 28, '30': 29, '31': 30, '32': 31, '33': 32, '34': 33, '35': 34, '36': 35, '37': 36, '38': 37, '39': 38, '40': 39, '41': 40, '42': 41, '43': 42, '45': 43, '46': 44, '47': 45, '48': 46, '49': 47, '50': 48, '51': 49, '52': 50, '53': 51, '54': 52, '57': 53, '59': 54, '60': 55, '61': 56, '62': 57, '63': 58, '64': 59, '65': 60, '66': 61, '67': 62, '68': 63, '69': 64, '70': 65, '71': 66, '72': 67, '73': 68, '74': 69, '75': 70, '76': 71, '77': 72, '78': 73, '79': 74, '80': 75, '81': 76, '82': 77, '83': 78, '84': 79, '85': 80, '86': 81, '87': 82, '88': 83, '94': 84, '95': 85, '97': 86, '101': 87, '109': 88, '111': 89, '114': 90, '115': 91, '120': 92, '123': 93, '126': 94, '127': 95, '128': 96, '129': 97, '132': 98, '133': 99}
Found 10551 images belonging to 100 classes.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_5 (InputLayer)         (None, None, None, 3)     0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, None, None, 64)    1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, None, None, 64)    36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, None, None, 64)    0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, None, None, 128)   73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, None, None, 128)   147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, None, None, 128)   0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, None, None, 256)   295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, None, None, 256)   0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, None, None, 512)   1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, None, None, 512)   0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, None, None, 512)   0
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
image_input (InputLayer)     (None, 128, 128, 3)       0
_________________________________________________________________
vgg16 (Model)                multiple                  14714688
_________________________________________________________________
flatten (Flatten)            (None, 8192)              0
_________________________________________________________________
fc2 (Dense)                  (None, 1024)              8389632
_________________________________________________________________
dropout_5 (Dropout)          (None, 1024)              0
_________________________________________________________________
dense_5 (Dense)              (None, 100)               102500
=================================================================
Total params: 23,206,820
Trainable params: 23,206,820
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
125/125 [==============================] - 68s - loss: 4.6135 - categorical_accuracy: 0.0104 - val_loss: 4.5852 - val_categorical_accuracy: 0.0098
Epoch 2/50
125/125 [==============================] - 68s - loss: 4.5805 - categorical_accuracy: 0.0130 - val_loss: 4.5617 - val_categorical_accuracy: 0.0106
Epoch 3/50
125/125 [==============================] - 65s - loss: 4.5679 - categorical_accuracy: 0.0130 - val_loss: 4.5477 - val_categorical_accuracy: 0.0099
Epoch 4/50
125/125 [==============================] - 65s - loss: 4.5586 - categorical_accuracy: 0.0119 - val_loss: 4.5410 - val_categorical_accuracy: 0.0121
Epoch 5/50
125/125 [==============================] - 73s - loss: 4.5594 - categorical_accuracy: 0.0119 - val_loss: 4.5268 - val_categorical_accuracy: 0.0096
Epoch 6/50
125/125 [==============================] - 75s - loss: 4.5462 - categorical_accuracy: 0.0112 - val_loss: 4.5270 - val_categorical_accuracy: 0.0132
Epoch 7/50
125/125 [==============================] - 72s - loss: 4.5530 - categorical_accuracy: 0.0114 - val_loss: 4.5220 - val_categorical_accuracy: 0.0116
Epoch 8/50
125/125 [==============================] - 69s - loss: 4.5513 - categorical_accuracy: 0.0118 - val_loss: 4.5193 - val_categorical_accuracy: 0.0102
Epoch 9/50
125/125 [==============================] - 73s - loss: 4.5482 - categorical_accuracy: 0.0101 - val_loss: 4.5179 - val_categorical_accuracy: 0.0172
Epoch 10/50
125/125 [==============================] - 73s - loss: 4.5486 - categorical_accuracy: 0.0113 - val_loss: 4.5186 - val_categorical_accuracy: 0.0152
Epoch 11/50
125/125 [==============================] - 67s - loss: 4.5486 - categorical_accuracy: 0.0116 - val_loss: 4.5151 - val_categorical_accuracy: 0.0135
Epoch 12/50
125/125 [==============================] - 66s - loss: 4.5469 - categorical_accuracy: 0.0130 - val_loss: 4.5194 - val_categorical_accuracy: 0.0146
Epoch 13/50
125/125 [==============================] - 62s - loss: 4.5486 - categorical_accuracy: 0.0120 - val_loss: 4.5204 - val_categorical_accuracy: 0.0121
Epoch 14/50
125/125 [==============================] - 68s - loss: 4.5476 - categorical_accuracy: 0.0106 - val_loss: 4.5211 - val_categorical_accuracy: 0.0145
Epoch 15/50
125/125 [==============================] - 62s - loss: 4.5482 - categorical_accuracy: 0.0096 - val_loss: 4.5156 - val_categorical_accuracy: 0.0093
Epoch 16/50
125/125 [==============================] - 63s - loss: 4.5459 - categorical_accuracy: 0.0108 - val_loss: 4.5235 - val_categorical_accuracy: 0.0158
Epoch 17/50
125/125 [==============================] - 65s - loss: 4.5499 - categorical_accuracy: 0.0127 - val_loss: 4.5162 - val_categorical_accuracy: 0.0119
Epoch 18/50
125/125 [==============================] - 63s - loss: 4.5455 - categorical_accuracy: 0.0107 - val_loss: 4.5161 - val_categorical_accuracy: 0.0146
Epoch 19/50
125/125 [==============================] - 64s - loss: 4.5496 - categorical_accuracy: 0.0137 - val_loss: 4.5191 - val_categorical_accuracy: 0.0092
Epoch 20/50
125/125 [==============================] - 63s - loss: 4.5467 - categorical_accuracy: 0.0108 - val_loss: 4.5122 - val_categorical_accuracy: 0.0162
Epoch 21/50
125/125 [==============================] - 61s - loss: 4.5464 - categorical_accuracy: 0.0110 - val_loss: 4.5244 - val_categorical_accuracy: 0.0134
Epoch 22/50
125/125 [==============================] - 67s - loss: 4.5492 - categorical_accuracy: 0.0122 - val_loss: 4.5190 - val_categorical_accuracy: 0.0141
Epoch 23/50
125/125 [==============================] - 72s - loss: 4.5446 - categorical_accuracy: 0.0126 - val_loss: 4.5174 - val_categorical_accuracy: 0.0152
Epoch 24/50
125/125 [==============================] - 68s - loss: 4.5476 - categorical_accuracy: 0.0135 - val_loss: 4.5143 - val_categorical_accuracy: 0.0112
Epoch 25/50
125/125 [==============================] - 72s - loss: 4.5504 - categorical_accuracy: 0.0110 - val_loss: 4.5191 - val_categorical_accuracy: 0.0104
Epoch 26/50
125/125 [==============================] - 70s - loss: 4.5478 - categorical_accuracy: 0.0119 - val_loss: 4.5170 - val_categorical_accuracy: 0.0152
Epoch 27/50
125/125 [==============================] - 67s - loss: 4.5467 - categorical_accuracy: 0.0106 - val_loss: 4.5237 - val_categorical_accuracy: 0.0097
Epoch 28/50
125/125 [==============================] - 71s - loss: 4.5439 - categorical_accuracy: 0.0116 - val_loss: 4.5112 - val_categorical_accuracy: 0.0104
Epoch 29/50
125/125 [==============================] - 68s - loss: 4.5482 - categorical_accuracy: 0.0106 - val_loss: 4.5204 - val_categorical_accuracy: 0.0028
Epoch 30/50
125/125 [==============================] - 69s - loss: 4.5476 - categorical_accuracy: 0.0107 - val_loss: 4.5158 - val_categorical_accuracy: 0.0144
Epoch 31/50
125/125 [==============================] - 71s - loss: 4.5481 - categorical_accuracy: 0.0130 - val_loss: 4.5208 - val_categorical_accuracy: 0.0126
Epoch 32/50
125/125 [==============================] - 65s - loss: 4.5465 - categorical_accuracy: 0.0118 - val_loss: 4.5208 - val_categorical_accuracy: 0.0140
Epoch 33/50
125/125 [==============================] - 66s - loss: 4.5474 - categorical_accuracy: 0.0107 - val_loss: 4.5195 - val_categorical_accuracy: 0.0152
Epoch 34/50
125/125 [==============================] - 68s - loss: 4.5434 - categorical_accuracy: 0.0129 - val_loss: 4.5173 - val_categorical_accuracy: 0.0149
Epoch 35/50
125/125 [==============================] - 67s - loss: 4.5472 - categorical_accuracy: 0.0096 - val_loss: 4.5159 - val_categorical_accuracy: 0.0211
Epoch 36/50
125/125 [==============================] - 65s - loss: 4.5480 - categorical_accuracy: 0.0103 - val_loss: 4.5177 - val_categorical_accuracy: 0.0149
Epoch 37/50
125/125 [==============================] - 68s - loss: 4.5499 - categorical_accuracy: 0.0134 - val_loss: 4.5173 - val_categorical_accuracy: 0.0155
Epoch 38/50
125/125 [==============================] - 66s - loss: 4.5454 - categorical_accuracy: 0.0127 - val_loss: 4.5173 - val_categorical_accuracy: 0.0149
Epoch 39/50
125/125 [==============================] - 68s - loss: 4.5439 - categorical_accuracy: 0.0121 - val_loss: 4.5176 - val_categorical_accuracy: 0.0152
Epoch 40/50
125/125 [==============================] - 63s - loss: 4.5504 - categorical_accuracy: 0.0114 - val_loss: 4.5196 - val_categorical_accuracy: 0.0168
Epoch 41/50
125/125 [==============================] - 66s - loss: 4.5483 - categorical_accuracy: 0.0118 - val_loss: 4.5152 - val_categorical_accuracy: 0.0098
Epoch 42/50
125/125 [==============================] - 65s - loss: 4.5455 - categorical_accuracy: 0.0122 - val_loss: 4.5205 - val_categorical_accuracy: 0.0131
Epoch 43/50
125/125 [==============================] - 66s - loss: 4.5486 - categorical_accuracy: 0.0129 - val_loss: 4.5133 - val_categorical_accuracy: 0.0136
Epoch 44/50
125/125 [==============================] - 69s - loss: 4.5474 - categorical_accuracy: 0.0108 - val_loss: 4.5201 - val_categorical_accuracy: 0.0131
Epoch 45/50
125/125 [==============================] - 68s - loss: 4.5459 - categorical_accuracy: 0.0108 - val_loss: 4.5210 - val_categorical_accuracy: 0.0130
Epoch 46/50
125/125 [==============================] - 69s - loss: 4.5464 - categorical_accuracy: 0.0101 - val_loss: 4.5183 - val_categorical_accuracy: 0.0134
Epoch 47/50
125/125 [==============================] - 66s - loss: 4.5448 - categorical_accuracy: 0.0132 - val_loss: 4.5135 - val_categorical_accuracy: 0.0149
Epoch 48/50
125/125 [==============================] - 65s - loss: 4.5480 - categorical_accuracy: 0.0097 - val_loss: 4.5251 - val_categorical_accuracy: 0.0155
Epoch 49/50
125/125 [==============================] - 68s - loss: 4.5467 - categorical_accuracy: 0.0094 - val_loss: 4.5152 - val_categorical_accuracy: 0.0154
Epoch 50/50
125/125 [==============================] - 64s - loss: 4.5478 - categorical_accuracy: 0.0107 - val_loss: 4.5202 - val_categorical_accuracy: 0.0140
----------------------
class labels are: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '57', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '94', '95', '97', '101', '109', '111', '114', '115', '120', '123', '126', '127', '128', '129', '132', '133']
Found 8153 images belonging to 100 classes.
{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14, '16': 15, '17': 16, '18': 17, '19': 18, '20': 19, '21': 20, '22': 21, '23': 22, '24': 23, '25': 24, '26': 25, '27': 26, '28': 27, '29': 28, '30': 29, '31': 30, '32': 31, '33': 32, '34': 33, '35': 34, '36': 35, '37': 36, '38': 37, '39': 38, '40': 39, '41': 40, '42': 41, '43': 42, '45': 43, '46': 44, '47': 45, '48': 46, '49': 47, '50': 48, '51': 49, '52': 50, '53': 51, '54': 52, '57': 53, '59': 54, '60': 55, '61': 56, '62': 57, '63': 58, '64': 59, '65': 60, '66': 61, '67': 62, '68': 63, '69': 64, '70': 65, '71': 66, '72': 67, '73': 68, '74': 69, '75': 70, '76': 71, '77': 72, '78': 73, '79': 74, '80': 75, '81': 76, '82': 77, '83': 78, '84': 79, '85': 80, '86': 81, '87': 82, '88': 83, '94': 84, '95': 85, '97': 86, '101': 87, '109': 88, '111': 89, '114': 90, '115': 91, '120': 92, '123': 93, '126': 94, '127': 95, '128': 96, '129': 97, '132': 98, '133': 99}
Found 10551 images belonging to 100 classes.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_6 (InputLayer)         (None, None, None, 3)     0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, None, None, 64)    1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, None, None, 64)    36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, None, None, 64)    0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, None, None, 128)   73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, None, None, 128)   147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, None, None, 128)   0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, None, None, 256)   295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, None, None, 256)   0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, None, None, 512)   1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, None, None, 512)   0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, None, None, 512)   0
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
image_input (InputLayer)     (None, 128, 128, 3)       0
_________________________________________________________________
vgg16 (Model)                multiple                  14714688
_________________________________________________________________
flatten (Flatten)            (None, 8192)              0
_________________________________________________________________
fc2 (Dense)                  (None, 1024)              8389632
_________________________________________________________________
dropout_6 (Dropout)          (None, 1024)              0
_________________________________________________________________
dense_6 (Dense)              (None, 100)               102500
=================================================================
Total params: 23,206,820
Trainable params: 23,206,820
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
125/125 [==============================] - 69s - loss: 4.6136 - categorical_accuracy: 0.0101 - val_loss: 4.5841 - val_categorical_accuracy: 0.0157
Epoch 2/50
125/125 [==============================] - 67s - loss: 4.5829 - categorical_accuracy: 0.0112 - val_loss: 4.5648 - val_categorical_accuracy: 0.0273
Epoch 3/50
125/125 [==============================] - 63s - loss: 4.5705 - categorical_accuracy: 0.0118 - val_loss: 4.5506 - val_categorical_accuracy: 0.0176
Epoch 4/50
125/125 [==============================] - 73s - loss: 4.5599 - categorical_accuracy: 0.0116 - val_loss: 4.5363 - val_categorical_accuracy: 0.0134
Epoch 5/50
125/125 [==============================] - 65s - loss: 4.5569 - categorical_accuracy: 0.0123 - val_loss: 4.5336 - val_categorical_accuracy: 0.0086
Epoch 6/50
125/125 [==============================] - 68s - loss: 4.5499 - categorical_accuracy: 0.0106 - val_loss: 4.5279 - val_categorical_accuracy: 0.0145
Epoch 7/50
125/125 [==============================] - 68s - loss: 4.5483 - categorical_accuracy: 0.0099 - val_loss: 4.5188 - val_categorical_accuracy: 0.0169
Epoch 8/50
125/125 [==============================] - 62s - loss: 4.5523 - categorical_accuracy: 0.0122 - val_loss: 4.5247 - val_categorical_accuracy: 0.0109
Epoch 9/50
125/125 [==============================] - 66s - loss: 4.5482 - categorical_accuracy: 0.0107 - val_loss: 4.5209 - val_categorical_accuracy: 0.0109
Epoch 10/50
125/125 [==============================] - 68s - loss: 4.5485 - categorical_accuracy: 0.0112 - val_loss: 4.5179 - val_categorical_accuracy: 0.0121
Epoch 11/50
125/125 [==============================] - 64s - loss: 4.5485 - categorical_accuracy: 0.0120 - val_loss: 4.5177 - val_categorical_accuracy: 0.0143
Epoch 12/50
125/125 [==============================] - 65s - loss: 4.5491 - categorical_accuracy: 0.0102 - val_loss: 4.5217 - val_categorical_accuracy: 0.0159
Epoch 13/50
125/125 [==============================] - 70s - loss: 4.5491 - categorical_accuracy: 0.0107 - val_loss: 4.5138 - val_categorical_accuracy: 0.0109
Epoch 14/50
125/125 [==============================] - 67s - loss: 4.5453 - categorical_accuracy: 0.0122 - val_loss: 4.5200 - val_categorical_accuracy: 0.0122
Epoch 15/50
125/125 [==============================] - 67s - loss: 4.5462 - categorical_accuracy: 0.0112 - val_loss: 4.5179 - val_categorical_accuracy: 0.0149
Epoch 16/50
125/125 [==============================] - 66s - loss: 4.5507 - categorical_accuracy: 0.0129 - val_loss: 4.5212 - val_categorical_accuracy: 0.0120
Epoch 17/50
125/125 [==============================] - 64s - loss: 4.5465 - categorical_accuracy: 0.0116 - val_loss: 4.5158 - val_categorical_accuracy: 0.0096
Epoch 18/50
125/125 [==============================] - 64s - loss: 4.5437 - categorical_accuracy: 0.0112 - val_loss: 4.5143 - val_categorical_accuracy: 0.0149
Epoch 19/50
125/125 [==============================] - 69s - loss: 4.5494 - categorical_accuracy: 0.0101 - val_loss: 4.5198 - val_categorical_accuracy: 0.0140
Epoch 20/50
125/125 [==============================] - 64s - loss: 4.5498 - categorical_accuracy: 0.0089 - val_loss: 4.5116 - val_categorical_accuracy: 0.0104
Epoch 21/50
125/125 [==============================] - 65s - loss: 4.5459 - categorical_accuracy: 0.0106 - val_loss: 4.5231 - val_categorical_accuracy: 0.0174
Epoch 22/50
125/125 [==============================] - 63s - loss: 4.5472 - categorical_accuracy: 0.0102 - val_loss: 4.5198 - val_categorical_accuracy: 0.0129
Epoch 23/50
125/125 [==============================] - 66s - loss: 4.5482 - categorical_accuracy: 0.0124 - val_loss: 4.5126 - val_categorical_accuracy: 0.0091
Epoch 24/50
125/125 [==============================] - 66s - loss: 4.5455 - categorical_accuracy: 0.0101 - val_loss: 4.5253 - val_categorical_accuracy: 0.0084
Epoch 25/50
125/125 [==============================] - 63s - loss: 4.5500 - categorical_accuracy: 0.0111 - val_loss: 4.5150 - val_categorical_accuracy: 0.0121
Epoch 26/50
125/125 [==============================] - 70s - loss: 4.5447 - categorical_accuracy: 0.0111 - val_loss: 4.5170 - val_categorical_accuracy: 0.0104
Epoch 27/50
125/125 [==============================] - 64s - loss: 4.5506 - categorical_accuracy: 0.0089 - val_loss: 4.5190 - val_categorical_accuracy: 0.0168
Epoch 28/50
125/125 [==============================] - 68s - loss: 4.5475 - categorical_accuracy: 0.0100 - val_loss: 4.5174 - val_categorical_accuracy: 0.0177
Epoch 29/50
125/125 [==============================] - 63s - loss: 4.5430 - categorical_accuracy: 0.0109 - val_loss: 4.5204 - val_categorical_accuracy: 0.0130
Epoch 30/50
125/125 [==============================] - 63s - loss: 4.5510 - categorical_accuracy: 0.0126 - val_loss: 4.5156 - val_categorical_accuracy: 0.0146
Epoch 31/50
125/125 [==============================] - 70s - loss: 4.5473 - categorical_accuracy: 0.0117 - val_loss: 4.5154 - val_categorical_accuracy: 0.0131
Epoch 32/50
125/125 [==============================] - 62s - loss: 4.5486 - categorical_accuracy: 0.0114 - val_loss: 4.5237 - val_categorical_accuracy: 0.0135
Epoch 33/50
125/125 [==============================] - 68s - loss: 4.5450 - categorical_accuracy: 0.0098 - val_loss: 4.5158 - val_categorical_accuracy: 0.0141
Epoch 34/50
125/125 [==============================] - 64s - loss: 4.5514 - categorical_accuracy: 0.0106 - val_loss: 4.5196 - val_categorical_accuracy: 0.0134
Epoch 35/50
125/125 [==============================] - 66s - loss: 4.5439 - categorical_accuracy: 0.0126 - val_loss: 4.5158 - val_categorical_accuracy: 0.0135
Epoch 36/50
125/125 [==============================] - 64s - loss: 4.5455 - categorical_accuracy: 0.0111 - val_loss: 4.5163 - val_categorical_accuracy: 0.0116
Epoch 37/50
125/125 [==============================] - 65s - loss: 4.5476 - categorical_accuracy: 0.0102 - val_loss: 4.5178 - val_categorical_accuracy: 0.0145
Epoch 38/50
125/125 [==============================] - 63s - loss: 4.5490 - categorical_accuracy: 0.0127 - val_loss: 4.5174 - val_categorical_accuracy: 0.0134
Epoch 39/50
125/125 [==============================] - 64s - loss: 4.5456 - categorical_accuracy: 0.0112 - val_loss: 4.5181 - val_categorical_accuracy: 0.0177
Epoch 40/50
125/125 [==============================] - 66s - loss: 4.5477 - categorical_accuracy: 0.0108 - val_loss: 4.5223 - val_categorical_accuracy: 0.0107
Epoch 41/50
125/125 [==============================] - 66s - loss: 4.5476 - categorical_accuracy: 0.0101 - val_loss: 4.5121 - val_categorical_accuracy: 0.0144
Epoch 42/50
125/125 [==============================] - 67s - loss: 4.5458 - categorical_accuracy: 0.0128 - val_loss: 4.5213 - val_categorical_accuracy: 0.0141
Epoch 43/50
125/125 [==============================] - 68s - loss: 4.5459 - categorical_accuracy: 0.0110 - val_loss: 4.5184 - val_categorical_accuracy: 0.0139
Epoch 44/50
125/125 [==============================] - 63s - loss: 4.5460 - categorical_accuracy: 0.0093 - val_loss: 4.5183 - val_categorical_accuracy: 0.0154
Epoch 45/50
125/125 [==============================] - 64s - loss: 4.5501 - categorical_accuracy: 0.0112 - val_loss: 4.5161 - val_categorical_accuracy: 0.0138
Epoch 46/50
125/125 [==============================] - 67s - loss: 4.5430 - categorical_accuracy: 0.0132 - val_loss: 4.5141 - val_categorical_accuracy: 0.0124
Epoch 47/50
125/125 [==============================] - 66s - loss: 4.5472 - categorical_accuracy: 0.0112 - val_loss: 4.5204 - val_categorical_accuracy: 0.0068
Epoch 48/50
125/125 [==============================] - 67s - loss: 4.5483 - categorical_accuracy: 0.0121 - val_loss: 4.5146 - val_categorical_accuracy: 0.0130
Epoch 49/50
125/125 [==============================] - 64s - loss: 4.5473 - categorical_accuracy: 0.0120 - val_loss: 4.5214 - val_categorical_accuracy: 0.0111
Epoch 50/50
125/125 [==============================] - 68s - loss: 4.5456 - categorical_accuracy: 0.0131 - val_loss: 4.5163 - val_categorical_accuracy: 0.0092
----------------------
class labels are: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '57', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '94', '95', '97', '101', '109', '111', '114', '115', '120', '123', '126', '127', '128', '129', '132', '133']
Found 8153 images belonging to 100 classes.
{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14, '16': 15, '17': 16, '18': 17, '19': 18, '20': 19, '21': 20, '22': 21, '23': 22, '24': 23, '25': 24, '26': 25, '27': 26, '28': 27, '29': 28, '30': 29, '31': 30, '32': 31, '33': 32, '34': 33, '35': 34, '36': 35, '37': 36, '38': 37, '39': 38, '40': 39, '41': 40, '42': 41, '43': 42, '45': 43, '46': 44, '47': 45, '48': 46, '49': 47, '50': 48, '51': 49, '52': 50, '53': 51, '54': 52, '57': 53, '59': 54, '60': 55, '61': 56, '62': 57, '63': 58, '64': 59, '65': 60, '66': 61, '67': 62, '68': 63, '69': 64, '70': 65, '71': 66, '72': 67, '73': 68, '74': 69, '75': 70, '76': 71, '77': 72, '78': 73, '79': 74, '80': 75, '81': 76, '82': 77, '83': 78, '84': 79, '85': 80, '86': 81, '87': 82, '88': 83, '94': 84, '95': 85, '97': 86, '101': 87, '109': 88, '111': 89, '114': 90, '115': 91, '120': 92, '123': 93, '126': 94, '127': 95, '128': 96, '129': 97, '132': 98, '133': 99}
Found 10551 images belonging to 100 classes.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_7 (InputLayer)         (None, None, None, 3)     0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, None, None, 64)    1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, None, None, 64)    36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, None, None, 64)    0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, None, None, 128)   73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, None, None, 128)   147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, None, None, 128)   0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, None, None, 256)   295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, None, None, 256)   0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, None, None, 512)   1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, None, None, 512)   0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, None, None, 512)   0
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
image_input (InputLayer)     (None, 128, 128, 3)       0
_________________________________________________________________
vgg16 (Model)                multiple                  14714688
_________________________________________________________________
flatten (Flatten)            (None, 8192)              0
_________________________________________________________________
fc2 (Dense)                  (None, 1024)              8389632
_________________________________________________________________
dropout_7 (Dropout)          (None, 1024)              0
_________________________________________________________________
dense_7 (Dense)              (None, 100)               102500
=================================================================
Total params: 23,206,820
Trainable params: 23,206,820
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
125/125 [==============================] - 66s - loss: 4.6113 - categorical_accuracy: 0.0091 - val_loss: 4.5857 - val_categorical_accuracy: 0.0096
Epoch 2/50
125/125 [==============================] - 65s - loss: 4.5839 - categorical_accuracy: 0.0112 - val_loss: 4.5689 - val_categorical_accuracy: 0.0167
Epoch 3/50
125/125 [==============================] - 71s - loss: 4.5711 - categorical_accuracy: 0.0120 - val_loss: 4.5547 - val_categorical_accuracy: 0.0168
Epoch 4/50
125/125 [==============================] - 64s - loss: 4.5611 - categorical_accuracy: 0.0120 - val_loss: 4.5445 - val_categorical_accuracy: 0.0116
Epoch 5/50
125/125 [==============================] - 63s - loss: 4.5595 - categorical_accuracy: 0.0123 - val_loss: 4.5325 - val_categorical_accuracy: 0.0152
Epoch 6/50
125/125 [==============================] - 64s - loss: 4.5553 - categorical_accuracy: 0.0119 - val_loss: 4.5268 - val_categorical_accuracy: 0.0145
Epoch 7/50
125/125 [==============================] - 62s - loss: 4.5478 - categorical_accuracy: 0.0142 - val_loss: 4.5282 - val_categorical_accuracy: 0.0134
Epoch 8/50
125/125 [==============================] - 69s - loss: 4.5483 - categorical_accuracy: 0.0110 - val_loss: 4.5180 - val_categorical_accuracy: 0.0127
Epoch 9/50
125/125 [==============================] - 61s - loss: 4.5502 - categorical_accuracy: 0.0113 - val_loss: 4.5197 - val_categorical_accuracy: 0.0136
Epoch 10/50
125/125 [==============================] - 62s - loss: 4.5462 - categorical_accuracy: 0.0102 - val_loss: 4.5211 - val_categorical_accuracy: 0.0129
Epoch 11/50
125/125 [==============================] - 64s - loss: 4.5491 - categorical_accuracy: 0.0123 - val_loss: 4.5164 - val_categorical_accuracy: 0.0166
Epoch 12/50
125/125 [==============================] - 67s - loss: 4.5461 - categorical_accuracy: 0.0111 - val_loss: 4.5174 - val_categorical_accuracy: 0.0144
Epoch 13/50
125/125 [==============================] - 66s - loss: 4.5464 - categorical_accuracy: 0.0117 - val_loss: 4.5219 - val_categorical_accuracy: 0.0106
Epoch 14/50
125/125 [==============================] - 68s - loss: 4.5492 - categorical_accuracy: 0.0116 - val_loss: 4.5237 - val_categorical_accuracy: 0.0158
Epoch 15/50
125/125 [==============================] - 64s - loss: 4.5496 - categorical_accuracy: 0.0128 - val_loss: 4.5137 - val_categorical_accuracy: 0.0144
Epoch 16/50
125/125 [==============================] - 62s - loss: 4.5461 - categorical_accuracy: 0.0112 - val_loss: 4.5171 - val_categorical_accuracy: 0.0107
Epoch 17/50
125/125 [==============================] - 66s - loss: 4.5443 - categorical_accuracy: 0.0099 - val_loss: 4.5195 - val_categorical_accuracy: 0.0146
Epoch 18/50
125/125 [==============================] - 63s - loss: 4.5497 - categorical_accuracy: 0.0129 - val_loss: 4.5185 - val_categorical_accuracy: 0.0154
Epoch 19/50
125/125 [==============================] - 64s - loss: 4.5473 - categorical_accuracy: 0.0119 - val_loss: 4.5183 - val_categorical_accuracy: 0.0140
Epoch 20/50
125/125 [==============================] - 67s - loss: 4.5452 - categorical_accuracy: 0.0112 - val_loss: 4.5172 - val_categorical_accuracy: 0.0124
Epoch 21/50
125/125 [==============================] - 64s - loss: 4.5513 - categorical_accuracy: 0.0097 - val_loss: 4.5189 - val_categorical_accuracy: 0.0111
Epoch 22/50
125/125 [==============================] - 64s - loss: 4.5471 - categorical_accuracy: 0.0103 - val_loss: 4.5172 - val_categorical_accuracy: 0.0167
Epoch 23/50
125/125 [==============================] - 63s - loss: 4.5486 - categorical_accuracy: 0.0095 - val_loss: 4.5190 - val_categorical_accuracy: 0.0157
Epoch 24/50
125/125 [==============================] - 65s - loss: 4.5470 - categorical_accuracy: 0.0128 - val_loss: 4.5201 - val_categorical_accuracy: 0.0117
Epoch 25/50
125/125 [==============================] - 64s - loss: 4.5450 - categorical_accuracy: 0.0107 - val_loss: 4.5173 - val_categorical_accuracy: 0.0114
Epoch 26/50
125/125 [==============================] - 66s - loss: 4.5476 - categorical_accuracy: 0.0110 - val_loss: 4.5175 - val_categorical_accuracy: 0.0109
Epoch 27/50
125/125 [==============================] - 63s - loss: 4.5485 - categorical_accuracy: 0.0132 - val_loss: 4.5127 - val_categorical_accuracy: 0.0237
Epoch 28/50
125/125 [==============================] - 66s - loss: 4.5509 - categorical_accuracy: 0.0120 - val_loss: 4.5203 - val_categorical_accuracy: 0.0114
Epoch 29/50
125/125 [==============================] - 67s - loss: 4.5442 - categorical_accuracy: 0.0101 - val_loss: 4.5185 - val_categorical_accuracy: 0.0097
Epoch 30/50
125/125 [==============================] - 63s - loss: 4.5482 - categorical_accuracy: 0.0113 - val_loss: 4.5127 - val_categorical_accuracy: 0.0139
Epoch 31/50
125/125 [==============================] - 66s - loss: 4.5463 - categorical_accuracy: 0.0142 - val_loss: 4.5258 - val_categorical_accuracy: 0.0146
Epoch 32/50
125/125 [==============================] - 66s - loss: 4.5437 - categorical_accuracy: 0.0127 - val_loss: 4.5227 - val_categorical_accuracy: 0.0122
Epoch 33/50
125/125 [==============================] - 63s - loss: 4.5471 - categorical_accuracy: 0.0116 - val_loss: 4.5126 - val_categorical_accuracy: 0.0154
Epoch 34/50
125/125 [==============================] - 62s - loss: 4.5492 - categorical_accuracy: 0.0122 - val_loss: 4.5175 - val_categorical_accuracy: 0.0088
Epoch 35/50
125/125 [==============================] - 61s - loss: 4.5444 - categorical_accuracy: 0.0112 - val_loss: 4.5259 - val_categorical_accuracy: 0.0143
Epoch 36/50
125/125 [==============================] - 66s - loss: 4.5502 - categorical_accuracy: 0.0111 - val_loss: 4.5191 - val_categorical_accuracy: 0.0139
Epoch 37/50
125/125 [==============================] - 65s - loss: 4.5459 - categorical_accuracy: 0.0106 - val_loss: 4.5162 - val_categorical_accuracy: 0.0150
Epoch 38/50
125/125 [==============================] - 65s - loss: 4.5464 - categorical_accuracy: 0.0110 - val_loss: 4.5165 - val_categorical_accuracy: 0.0136
Epoch 39/50
125/125 [==============================] - 66s - loss: 4.5478 - categorical_accuracy: 0.0121 - val_loss: 4.5199 - val_categorical_accuracy: 0.0144
Epoch 40/50
125/125 [==============================] - 64s - loss: 4.5455 - categorical_accuracy: 0.0112 - val_loss: 4.5149 - val_categorical_accuracy: 0.0163
Epoch 41/50
125/125 [==============================] - 61s - loss: 4.5483 - categorical_accuracy: 0.0087 - val_loss: 4.5157 - val_categorical_accuracy: 0.0154
Epoch 42/50
125/125 [==============================] - 62s - loss: 4.5478 - categorical_accuracy: 0.0117 - val_loss: 4.5197 - val_categorical_accuracy: 0.0129
Epoch 43/50
125/125 [==============================] - 64s - loss: 4.5469 - categorical_accuracy: 0.0138 - val_loss: 4.5167 - val_categorical_accuracy: 0.0141
Epoch 44/50
125/125 [==============================] - 63s - loss: 4.5469 - categorical_accuracy: 0.0111 - val_loss: 4.5230 - val_categorical_accuracy: 0.0164
Epoch 45/50
125/125 [==============================] - 62s - loss: 4.5453 - categorical_accuracy: 0.0130 - val_loss: 4.5115 - val_categorical_accuracy: 0.0280
Epoch 46/50
125/125 [==============================] - 67s - loss: 4.5484 - categorical_accuracy: 0.0132 - val_loss: 4.5193 - val_categorical_accuracy: 0.0136
Epoch 47/50
125/125 [==============================] - 64s - loss: 4.5481 - categorical_accuracy: 0.0127 - val_loss: 4.5163 - val_categorical_accuracy: 0.0106
Epoch 48/50
125/125 [==============================] - 65s - loss: 4.5443 - categorical_accuracy: 0.0113 - val_loss: 4.5266 - val_categorical_accuracy: 0.0084
Epoch 49/50
125/125 [==============================] - 69s - loss: 4.5473 - categorical_accuracy: 0.0106 - val_loss: 4.5129 - val_categorical_accuracy: 0.0121
Epoch 50/50
125/125 [==============================] - 66s - loss: 4.5468 - categorical_accuracy: 0.0101 - val_loss: 4.5189 - val_categorical_accuracy: 0.0120
----------------------
class labels are: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '57', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '94', '95', '97', '101', '109', '111', '114', '115', '120', '123', '126', '127', '128', '129', '132', '133']
Found 8153 images belonging to 100 classes.
{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14, '16': 15, '17': 16, '18': 17, '19': 18, '20': 19, '21': 20, '22': 21, '23': 22, '24': 23, '25': 24, '26': 25, '27': 26, '28': 27, '29': 28, '30': 29, '31': 30, '32': 31, '33': 32, '34': 33, '35': 34, '36': 35, '37': 36, '38': 37, '39': 38, '40': 39, '41': 40, '42': 41, '43': 42, '45': 43, '46': 44, '47': 45, '48': 46, '49': 47, '50': 48, '51': 49, '52': 50, '53': 51, '54': 52, '57': 53, '59': 54, '60': 55, '61': 56, '62': 57, '63': 58, '64': 59, '65': 60, '66': 61, '67': 62, '68': 63, '69': 64, '70': 65, '71': 66, '72': 67, '73': 68, '74': 69, '75': 70, '76': 71, '77': 72, '78': 73, '79': 74, '80': 75, '81': 76, '82': 77, '83': 78, '84': 79, '85': 80, '86': 81, '87': 82, '88': 83, '94': 84, '95': 85, '97': 86, '101': 87, '109': 88, '111': 89, '114': 90, '115': 91, '120': 92, '123': 93, '126': 94, '127': 95, '128': 96, '129': 97, '132': 98, '133': 99}
Found 10551 images belonging to 100 classes.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_8 (InputLayer)         (None, None, None, 3)     0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, None, None, 64)    1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, None, None, 64)    36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, None, None, 64)    0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, None, None, 128)   73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, None, None, 128)   147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, None, None, 128)   0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, None, None, 256)   295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, None, None, 256)   0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, None, None, 512)   1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, None, None, 512)   0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, None, None, 512)   0
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
image_input (InputLayer)     (None, 128, 128, 3)       0
_________________________________________________________________
vgg16 (Model)                multiple                  14714688
_________________________________________________________________
flatten (Flatten)            (None, 8192)              0
_________________________________________________________________
fc2 (Dense)                  (None, 1024)              8389632
_________________________________________________________________
dropout_8 (Dropout)          (None, 1024)              0
_________________________________________________________________
dense_8 (Dense)              (None, 100)               102500
=================================================================
Total params: 23,206,820
Trainable params: 23,206,820
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
125/125 [==============================] - 72s - loss: 11.9795 - categorical_accuracy: 0.0115 - val_loss: 15.9512 - val_categorical_accuracy: 0.0104
Epoch 2/50
125/125 [==============================] - 64s - loss: 15.9247 - categorical_accuracy: 0.0120 - val_loss: 16.0041 - val_categorical_accuracy: 0.0071
Epoch 3/50
125/125 [==============================] - 64s - loss: 15.9085 - categorical_accuracy: 0.0130 - val_loss: 15.9662 - val_categorical_accuracy: 0.0094
Epoch 4/50
125/125 [==============================] - 62s - loss: 15.9211 - categorical_accuracy: 0.0122 - val_loss: 15.9716 - val_categorical_accuracy: 0.0091
Epoch 5/50
125/125 [==============================] - 63s - loss: 15.8865 - categorical_accuracy: 0.0119 - val_loss: 15.9675 - val_categorical_accuracy: 0.0093
Epoch 6/50
125/125 [==============================] - 65s - loss: 15.9300 - categorical_accuracy: 0.0117 - val_loss: 15.9621 - val_categorical_accuracy: 0.0097
Epoch 7/50
125/125 [==============================] - 68s - loss: 15.9135 - categorical_accuracy: 0.0127 - val_loss: 15.9756 - val_categorical_accuracy: 0.0088
Epoch 8/50
125/125 [==============================] - 62s - loss: 15.9193 - categorical_accuracy: 0.0123 - val_loss: 15.9580 - val_categorical_accuracy: 0.0099
Epoch 9/50
125/125 [==============================] - 61s - loss: 15.9265 - categorical_accuracy: 0.0119 - val_loss: 15.9716 - val_categorical_accuracy: 0.0091
Epoch 10/50
125/125 [==============================] - 66s - loss: 15.9193 - categorical_accuracy: 0.0123 - val_loss: 16.0001 - val_categorical_accuracy: 0.0073
Epoch 11/50
125/125 [==============================] - 71s - loss: 15.9117 - categorical_accuracy: 0.0128 - val_loss: 15.9334 - val_categorical_accuracy: 0.0115
Epoch 12/50
125/125 [==============================] - 64s - loss: 15.9211 - categorical_accuracy: 0.0122 - val_loss: 15.9594 - val_categorical_accuracy: 0.0098
Epoch 13/50
125/125 [==============================] - 64s - loss: 15.9229 - categorical_accuracy: 0.0121 - val_loss: 15.9634 - val_categorical_accuracy: 0.0096
Epoch 14/50
125/125 [==============================] - 63s - loss: 15.9157 - categorical_accuracy: 0.0126 - val_loss: 15.9785 - val_categorical_accuracy: 0.0087
Epoch 15/50
125/125 [==============================] - 65s - loss: 15.9390 - categorical_accuracy: 0.0111 - val_loss: 15.9756 - val_categorical_accuracy: 0.0088
Epoch 16/50
125/125 [==============================] - 65s - loss: 15.9103 - categorical_accuracy: 0.0129 - val_loss: 15.9621 - val_categorical_accuracy: 0.0097
Epoch 17/50
125/125 [==============================] - 64s - loss: 15.9318 - categorical_accuracy: 0.0116 - val_loss: 15.9716 - val_categorical_accuracy: 0.0091
Epoch 18/50
125/125 [==============================] - 66s - loss: 15.9068 - categorical_accuracy: 0.0131 - val_loss: 15.9553 - val_categorical_accuracy: 0.0101
Epoch 19/50
125/125 [==============================] - 66s - loss: 15.9193 - categorical_accuracy: 0.0123 - val_loss: 15.9662 - val_categorical_accuracy: 0.0094
Epoch 20/50
125/125 [==============================] - 65s - loss: 15.9207 - categorical_accuracy: 0.0122 - val_loss: 15.9716 - val_categorical_accuracy: 0.0091
Epoch 21/50
125/125 [==============================] - 66s - loss: 15.9189 - categorical_accuracy: 0.0124 - val_loss: 15.9675 - val_categorical_accuracy: 0.0093
Epoch 22/50
125/125 [==============================] - 66s - loss: 15.9118 - categorical_accuracy: 0.0128 - val_loss: 15.9390 - val_categorical_accuracy: 0.0111
Epoch 23/50
125/125 [==============================] - 67s - loss: 15.9336 - categorical_accuracy: 0.0114 - val_loss: 15.9919 - val_categorical_accuracy: 0.0078
Epoch 24/50
125/125 [==============================] - 62s - loss: 15.9175 - categorical_accuracy: 0.0124 - val_loss: 15.9539 - val_categorical_accuracy: 0.0102
Epoch 25/50
125/125 [==============================] - 66s - loss: 15.9300 - categorical_accuracy: 0.0117 - val_loss: 15.9756 - val_categorical_accuracy: 0.0088
Epoch 26/50
125/125 [==============================] - 64s - loss: 15.9300 - categorical_accuracy: 0.0117 - val_loss: 15.9634 - val_categorical_accuracy: 0.0096
Epoch 27/50
125/125 [==============================] - 65s - loss: 15.8960 - categorical_accuracy: 0.0138 - val_loss: 15.9580 - val_categorical_accuracy: 0.0099
Epoch 28/50
125/125 [==============================] - 65s - loss: 15.9265 - categorical_accuracy: 0.0119 - val_loss: 15.9756 - val_categorical_accuracy: 0.0088
Epoch 29/50
125/125 [==============================] - 63s - loss: 15.9229 - categorical_accuracy: 0.0121 - val_loss: 15.9703 - val_categorical_accuracy: 0.0092
Epoch 30/50
125/125 [==============================] - 66s - loss: 15.9046 - categorical_accuracy: 0.0132 - val_loss: 15.9594 - val_categorical_accuracy: 0.0098
Epoch 31/50
125/125 [==============================] - 63s - loss: 15.9318 - categorical_accuracy: 0.0116 - val_loss: 15.9838 - val_categorical_accuracy: 0.0083
Epoch 32/50
125/125 [==============================] - 63s - loss: 15.9185 - categorical_accuracy: 0.0124 - val_loss: 15.9580 - val_categorical_accuracy: 0.0099
Epoch 33/50
125/125 [==============================] - 62s - loss: 15.9193 - categorical_accuracy: 0.0123 - val_loss: 15.9634 - val_categorical_accuracy: 0.0096
Epoch 34/50
125/125 [==============================] - 66s - loss: 15.9157 - categorical_accuracy: 0.0126 - val_loss: 15.9756 - val_categorical_accuracy: 0.0088
Epoch 35/50
125/125 [==============================] - 66s - loss: 15.9175 - categorical_accuracy: 0.0124 - val_loss: 15.9498 - val_categorical_accuracy: 0.0104
Epoch 36/50
125/125 [==============================] - 63s - loss: 15.9390 - categorical_accuracy: 0.0111 - val_loss: 16.0082 - val_categorical_accuracy: 0.0068
Epoch 37/50
125/125 [==============================] - 65s - loss: 15.9010 - categorical_accuracy: 0.0135 - val_loss: 15.9211 - val_categorical_accuracy: 0.0122
Epoch 38/50
125/125 [==============================] - 62s - loss: 15.9085 - categorical_accuracy: 0.0130 - val_loss: 15.9960 - val_categorical_accuracy: 0.0076
Epoch 39/50
125/125 [==============================] - 63s - loss: 15.9332 - categorical_accuracy: 0.0115 - val_loss: 15.9512 - val_categorical_accuracy: 0.0104
Epoch 40/50
125/125 [==============================] - 62s - loss: 15.9121 - categorical_accuracy: 0.0128 - val_loss: 15.9950 - val_categorical_accuracy: 0.0076
Epoch 41/50
125/125 [==============================] - 64s - loss: 15.9283 - categorical_accuracy: 0.0118 - val_loss: 15.9594 - val_categorical_accuracy: 0.0098
Epoch 42/50
125/125 [==============================] - 65s - loss: 15.9211 - categorical_accuracy: 0.0122 - val_loss: 15.9594 - val_categorical_accuracy: 0.0098
Epoch 43/50
125/125 [==============================] - 63s - loss: 15.9175 - categorical_accuracy: 0.0124 - val_loss: 15.9634 - val_categorical_accuracy: 0.0096
Epoch 44/50
125/125 [==============================] - 64s - loss: 15.9297 - categorical_accuracy: 0.0117 - val_loss: 15.9675 - val_categorical_accuracy: 0.0093
Epoch 45/50
125/125 [==============================] - 63s - loss: 15.9211 - categorical_accuracy: 0.0122 - val_loss: 15.9868 - val_categorical_accuracy: 0.0081
Epoch 46/50
125/125 [==============================] - 63s - loss: 15.8960 - categorical_accuracy: 0.0138 - val_loss: 15.9431 - val_categorical_accuracy: 0.0109
Epoch 47/50
125/125 [==============================] - 63s - loss: 15.9297 - categorical_accuracy: 0.0117 - val_loss: 15.9675 - val_categorical_accuracy: 0.0093
Epoch 48/50
125/125 [==============================] - 68s - loss: 15.9279 - categorical_accuracy: 0.0118 - val_loss: 15.9703 - val_categorical_accuracy: 0.0092
Epoch 49/50
125/125 [==============================] - 63s - loss: 15.9315 - categorical_accuracy: 0.0116 - val_loss: 15.9309 - val_categorical_accuracy: 0.0116
Epoch 50/50
125/125 [==============================] - 63s - loss: 15.8978 - categorical_accuracy: 0.0137 - val_loss: 15.9991 - val_categorical_accuracy: 0.0074
----------------------
class labels are: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '57', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '94', '95', '97', '101', '109', '111', '114', '115', '120', '123', '126', '127', '128', '129', '132', '133']
Found 8153 images belonging to 100 classes.
{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14, '16': 15, '17': 16, '18': 17, '19': 18, '20': 19, '21': 20, '22': 21, '23': 22, '24': 23, '25': 24, '26': 25, '27': 26, '28': 27, '29': 28, '30': 29, '31': 30, '32': 31, '33': 32, '34': 33, '35': 34, '36': 35, '37': 36, '38': 37, '39': 38, '40': 39, '41': 40, '42': 41, '43': 42, '45': 43, '46': 44, '47': 45, '48': 46, '49': 47, '50': 48, '51': 49, '52': 50, '53': 51, '54': 52, '57': 53, '59': 54, '60': 55, '61': 56, '62': 57, '63': 58, '64': 59, '65': 60, '66': 61, '67': 62, '68': 63, '69': 64, '70': 65, '71': 66, '72': 67, '73': 68, '74': 69, '75': 70, '76': 71, '77': 72, '78': 73, '79': 74, '80': 75, '81': 76, '82': 77, '83': 78, '84': 79, '85': 80, '86': 81, '87': 82, '88': 83, '94': 84, '95': 85, '97': 86, '101': 87, '109': 88, '111': 89, '114': 90, '115': 91, '120': 92, '123': 93, '126': 94, '127': 95, '128': 96, '129': 97, '132': 98, '133': 99}
Found 10551 images belonging to 100 classes.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_9 (InputLayer)         (None, None, None, 3)     0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, None, None, 64)    1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, None, None, 64)    36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, None, None, 64)    0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, None, None, 128)   73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, None, None, 128)   147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, None, None, 128)   0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, None, None, 256)   295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, None, None, 256)   0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, None, None, 512)   1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, None, None, 512)   0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, None, None, 512)   0
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
image_input (InputLayer)     (None, 128, 128, 3)       0
_________________________________________________________________
vgg16 (Model)                multiple                  14714688
_________________________________________________________________
flatten (Flatten)            (None, 8192)              0
_________________________________________________________________
fc2 (Dense)                  (None, 1024)              8389632
_________________________________________________________________
dropout_9 (Dropout)          (None, 1024)              0
_________________________________________________________________
dense_9 (Dense)              (None, 100)               102500
=================================================================
Total params: 23,206,820
Trainable params: 23,206,820
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
125/125 [==============================] - 71s - loss: 4.6142 - categorical_accuracy: 0.0107 - val_loss: 4.5850 - val_categorical_accuracy: 0.0149
Epoch 2/50
125/125 [==============================] - 65s - loss: 4.5821 - categorical_accuracy: 0.0107 - val_loss: 4.5667 - val_categorical_accuracy: 0.0114
Epoch 3/50
125/125 [==============================] - 63s - loss: 4.5714 - categorical_accuracy: 0.0111 - val_loss: 4.5526 - val_categorical_accuracy: 0.0135
Epoch 4/50
125/125 [==============================] - 67s - loss: 4.5618 - categorical_accuracy: 0.0116 - val_loss: 4.5409 - val_categorical_accuracy: 0.0096
Epoch 5/50
125/125 [==============================] - 68s - loss: 4.5560 - categorical_accuracy: 0.0122 - val_loss: 4.5349 - val_categorical_accuracy: 0.0152
Epoch 6/50
125/125 [==============================] - 63s - loss: 4.5536 - categorical_accuracy: 0.0126 - val_loss: 4.5311 - val_categorical_accuracy: 0.0122
Epoch 7/50
125/125 [==============================] - 61s - loss: 4.5491 - categorical_accuracy: 0.0113 - val_loss: 4.5200 - val_categorical_accuracy: 0.0106
Epoch 8/50
125/125 [==============================] - 63s - loss: 4.5507 - categorical_accuracy: 0.0133 - val_loss: 4.5213 - val_categorical_accuracy: 0.0145
Epoch 9/50
125/125 [==============================] - 62s - loss: 4.5488 - categorical_accuracy: 0.0090 - val_loss: 4.5239 - val_categorical_accuracy: 0.0169
Epoch 10/50
125/125 [==============================] - 65s - loss: 4.5472 - categorical_accuracy: 0.0111 - val_loss: 4.5145 - val_categorical_accuracy: 0.0078
Epoch 11/50
125/125 [==============================] - 62s - loss: 4.5472 - categorical_accuracy: 0.0098 - val_loss: 4.5268 - val_categorical_accuracy: 0.0138
Epoch 12/50
125/125 [==============================] - 63s - loss: 4.5470 - categorical_accuracy: 0.0121 - val_loss: 4.5154 - val_categorical_accuracy: 0.0098
Epoch 13/50
125/125 [==============================] - 67s - loss: 4.5507 - categorical_accuracy: 0.0111 - val_loss: 4.5151 - val_categorical_accuracy: 0.0111
Epoch 14/50
125/125 [==============================] - 67s - loss: 4.5457 - categorical_accuracy: 0.0129 - val_loss: 4.5165 - val_categorical_accuracy: 0.0143
Epoch 15/50
125/125 [==============================] - 71s - loss: 4.5496 - categorical_accuracy: 0.0109 - val_loss: 4.5185 - val_categorical_accuracy: 0.0091
Epoch 16/50
125/125 [==============================] - 62s - loss: 4.5451 - categorical_accuracy: 0.0110 - val_loss: 4.5205 - val_categorical_accuracy: 0.0140
Epoch 17/50
125/125 [==============================] - 63s - loss: 4.5465 - categorical_accuracy: 0.0118 - val_loss: 4.5179 - val_categorical_accuracy: 0.0114
Epoch 18/50
125/125 [==============================] - 66s - loss: 4.5514 - categorical_accuracy: 0.0113 - val_loss: 4.5132 - val_categorical_accuracy: 0.0071
Epoch 19/50
125/125 [==============================] - 64s - loss: 4.5452 - categorical_accuracy: 0.0106 - val_loss: 4.5207 - val_categorical_accuracy: 0.0092
Epoch 20/50
125/125 [==============================] - 62s - loss: 4.5485 - categorical_accuracy: 0.0130 - val_loss: 4.5184 - val_categorical_accuracy: 0.0134
Epoch 21/50
125/125 [==============================] - 65s - loss: 4.5457 - categorical_accuracy: 0.0100 - val_loss: 4.5195 - val_categorical_accuracy: 0.0149
Epoch 22/50
125/125 [==============================] - 62s - loss: 4.5492 - categorical_accuracy: 0.0118 - val_loss: 4.5106 - val_categorical_accuracy: 0.0139
Epoch 23/50
125/125 [==============================] - 64s - loss: 4.5450 - categorical_accuracy: 0.0102 - val_loss: 4.5216 - val_categorical_accuracy: 0.0149
Epoch 24/50
125/125 [==============================] - 66s - loss: 4.5460 - categorical_accuracy: 0.0121 - val_loss: 4.5173 - val_categorical_accuracy: 0.0122
Epoch 25/50
125/125 [==============================] - 70s - loss: 4.5458 - categorical_accuracy: 0.0124 - val_loss: 4.5209 - val_categorical_accuracy: 0.0126
Epoch 26/50
125/125 [==============================] - 64s - loss: 4.5481 - categorical_accuracy: 0.0118 - val_loss: 4.5191 - val_categorical_accuracy: 0.0146
Epoch 27/50
125/125 [==============================] - 64s - loss: 4.5465 - categorical_accuracy: 0.0115 - val_loss: 4.5197 - val_categorical_accuracy: 0.0160
Epoch 28/50
125/125 [==============================] - 67s - loss: 4.5481 - categorical_accuracy: 0.0119 - val_loss: 4.5146 - val_categorical_accuracy: 0.0177
Epoch 29/50
125/125 [==============================] - 62s - loss: 4.5447 - categorical_accuracy: 0.0113 - val_loss: 4.5223 - val_categorical_accuracy: 0.0138
Epoch 30/50
125/125 [==============================] - 63s - loss: 4.5500 - categorical_accuracy: 0.0100 - val_loss: 4.5233 - val_categorical_accuracy: 0.0131
Epoch 31/50
125/125 [==============================] - 64s - loss: 4.5455 - categorical_accuracy: 0.0112 - val_loss: 4.5137 - val_categorical_accuracy: 0.0134
Epoch 32/50
125/125 [==============================] - 62s - loss: 4.5476 - categorical_accuracy: 0.0104 - val_loss: 4.5193 - val_categorical_accuracy: 0.0140
Epoch 33/50
125/125 [==============================] - 62s - loss: 4.5468 - categorical_accuracy: 0.0132 - val_loss: 4.5150 - val_categorical_accuracy: 0.0124
Epoch 34/50
125/125 [==============================] - 61s - loss: 4.5442 - categorical_accuracy: 0.0119 - val_loss: 4.5191 - val_categorical_accuracy: 0.0144
Epoch 35/50
125/125 [==============================] - 63s - loss: 4.5501 - categorical_accuracy: 0.0117 - val_loss: 4.5202 - val_categorical_accuracy: 0.0117
Epoch 36/50
125/125 [==============================] - 64s - loss: 4.5459 - categorical_accuracy: 0.0123 - val_loss: 4.5155 - val_categorical_accuracy: 0.0116
Epoch 37/50
125/125 [==============================] - 63s - loss: 4.5448 - categorical_accuracy: 0.0118 - val_loss: 4.5155 - val_categorical_accuracy: 0.0115
Epoch 38/50
125/125 [==============================] - 63s - loss: 4.5490 - categorical_accuracy: 0.0109 - val_loss: 4.5194 - val_categorical_accuracy: 0.0126
Epoch 39/50
125/125 [==============================] - 65s - loss: 4.5469 - categorical_accuracy: 0.0132 - val_loss: 4.5197 - val_categorical_accuracy: 0.0081
Epoch 40/50
125/125 [==============================] - 63s - loss: 4.5445 - categorical_accuracy: 0.0104 - val_loss: 4.5248 - val_categorical_accuracy: 0.0127
Epoch 41/50
125/125 [==============================] - 65s - loss: 4.5466 - categorical_accuracy: 0.0127 - val_loss: 4.5167 - val_categorical_accuracy: 0.0121
Epoch 42/50
125/125 [==============================] - 68s - loss: 4.5474 - categorical_accuracy: 0.0103 - val_loss: 4.5167 - val_categorical_accuracy: 0.0116
Epoch 43/50
125/125 [==============================] - 62s - loss: 4.5463 - categorical_accuracy: 0.0122 - val_loss: 4.5242 - val_categorical_accuracy: 0.0119
Epoch 44/50
125/125 [==============================] - 64s - loss: 4.5449 - categorical_accuracy: 0.0108 - val_loss: 4.5173 - val_categorical_accuracy: 0.0129
Epoch 45/50
125/125 [==============================] - 63s - loss: 4.5449 - categorical_accuracy: 0.0101 - val_loss: 4.5110 - val_categorical_accuracy: 0.0117
Epoch 46/50
125/125 [==============================] - 65s - loss: 4.5486 - categorical_accuracy: 0.0113 - val_loss: 4.5218 - val_categorical_accuracy: 0.0134
Epoch 47/50
125/125 [==============================] - 66s - loss: 4.5488 - categorical_accuracy: 0.0126 - val_loss: 4.5144 - val_categorical_accuracy: 0.0086
Epoch 48/50
125/125 [==============================] - 63s - loss: 4.5448 - categorical_accuracy: 0.0110 - val_loss: 4.5215 - val_categorical_accuracy: 0.0132
Epoch 49/50
125/125 [==============================] - 69s - loss: 4.5467 - categorical_accuracy: 0.0112 - val_loss: 4.5163 - val_categorical_accuracy: 0.0124
Epoch 50/50
125/125 [==============================] - 63s - loss: 4.5467 - categorical_accuracy: 0.0117 - val_loss: 4.5175 - val_categorical_accuracy: 0.0140
----------------------
class labels are: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '57', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '94', '95', '97', '101', '109', '111', '114', '115', '120', '123', '126', '127', '128', '129', '132', '133']
Found 8153 images belonging to 100 classes.
{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14, '16': 15, '17': 16, '18': 17, '19': 18, '20': 19, '21': 20, '22': 21, '23': 22, '24': 23, '25': 24, '26': 25, '27': 26, '28': 27, '29': 28, '30': 29, '31': 30, '32': 31, '33': 32, '34': 33, '35': 34, '36': 35, '37': 36, '38': 37, '39': 38, '40': 39, '41': 40, '42': 41, '43': 42, '45': 43, '46': 44, '47': 45, '48': 46, '49': 47, '50': 48, '51': 49, '52': 50, '53': 51, '54': 52, '57': 53, '59': 54, '60': 55, '61': 56, '62': 57, '63': 58, '64': 59, '65': 60, '66': 61, '67': 62, '68': 63, '69': 64, '70': 65, '71': 66, '72': 67, '73': 68, '74': 69, '75': 70, '76': 71, '77': 72, '78': 73, '79': 74, '80': 75, '81': 76, '82': 77, '83': 78, '84': 79, '85': 80, '86': 81, '87': 82, '88': 83, '94': 84, '95': 85, '97': 86, '101': 87, '109': 88, '111': 89, '114': 90, '115': 91, '120': 92, '123': 93, '126': 94, '127': 95, '128': 96, '129': 97, '132': 98, '133': 99}
Found 10551 images belonging to 100 classes.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_10 (InputLayer)        (None, None, None, 3)     0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, None, None, 64)    1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, None, None, 64)    36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, None, None, 64)    0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, None, None, 128)   73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, None, None, 128)   147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, None, None, 128)   0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, None, None, 256)   295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, None, None, 256)   590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, None, None, 256)   0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, None, None, 512)   1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, None, None, 512)   0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, None, None, 512)   2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, None, None, 512)   0
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
image_input (InputLayer)     (None, 128, 128, 3)       0
_________________________________________________________________
vgg16 (Model)                multiple                  14714688
_________________________________________________________________
flatten (Flatten)            (None, 8192)              0
_________________________________________________________________
fc2 (Dense)                  (None, 1024)              8389632
_________________________________________________________________
dropout_10 (Dropout)         (None, 1024)              0
_________________________________________________________________
dense_10 (Dense)             (None, 100)               102500
=================================================================
Total params: 23,206,820
Trainable params: 23,206,820
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
125/125 [==============================] - 66s - loss: 4.6232 - categorical_accuracy: 0.0114 - val_loss: 4.5859 - val_categorical_accuracy: 0.0101
Epoch 2/50
125/125 [==============================] - 64s - loss: 4.5830 - categorical_accuracy: 0.0099 - val_loss: 4.5666 - val_categorical_accuracy: 0.0126
Epoch 3/50
125/125 [==============================] - 69s - loss: 4.5712 - categorical_accuracy: 0.0127 - val_loss: 4.5578 - val_categorical_accuracy: 0.0155
Epoch 4/50
125/125 [==============================] - 65s - loss: 4.5617 - categorical_accuracy: 0.0122 - val_loss: 4.5436 - val_categorical_accuracy: 0.0124
Epoch 5/50
125/125 [==============================] - 67s - loss: 4.5567 - categorical_accuracy: 0.0109 - val_loss: 4.5321 - val_categorical_accuracy: 0.0157
Epoch 6/50
125/125 [==============================] - 67s - loss: 4.5504 - categorical_accuracy: 0.0129 - val_loss: 4.5262 - val_categorical_accuracy: 0.0122
Epoch 7/50
125/125 [==============================] - 70s - loss: 4.5520 - categorical_accuracy: 0.0108 - val_loss: 4.5267 - val_categorical_accuracy: 0.0111
Epoch 8/50
125/125 [==============================] - 70s - loss: 4.5491 - categorical_accuracy: 0.0118 - val_loss: 4.5231 - val_categorical_accuracy: 0.0153
Epoch 9/50
125/125 [==============================] - 66s - loss: 4.5472 - categorical_accuracy: 0.0127 - val_loss: 4.5182 - val_categorical_accuracy: 0.0177
Epoch 10/50
125/125 [==============================] - 67s - loss: 4.5496 - categorical_accuracy: 0.0111 - val_loss: 4.5210 - val_categorical_accuracy: 0.0121
Epoch 11/50
125/125 [==============================] - 63s - loss: 4.5469 - categorical_accuracy: 0.0124 - val_loss: 4.5174 - val_categorical_accuracy: 0.0168
Epoch 12/50
125/125 [==============================] - 68s - loss: 4.5467 - categorical_accuracy: 0.0109 - val_loss: 4.5174 - val_categorical_accuracy: 0.0159
Epoch 13/50
125/125 [==============================] - 65s - loss: 4.5485 - categorical_accuracy: 0.0126 - val_loss: 4.5187 - val_categorical_accuracy: 0.0164
Epoch 14/50
125/125 [==============================] - 60s - loss: 4.5495 - categorical_accuracy: 0.0118 - val_loss: 4.5266 - val_categorical_accuracy: 0.0132
Epoch 15/50
125/125 [==============================] - 65s - loss: 4.5445 - categorical_accuracy: 0.0137 - val_loss: 4.5101 - val_categorical_accuracy: 0.0146
Epoch 16/50
125/125 [==============================] - 65s - loss: 4.5461 - categorical_accuracy: 0.0111 - val_loss: 4.5219 - val_categorical_accuracy: 0.0143
Epoch 17/50
125/125 [==============================] - 62s - loss: 4.5522 - categorical_accuracy: 0.0109 - val_loss: 4.5204 - val_categorical_accuracy: 0.0134
Epoch 18/50
125/125 [==============================] - 65s - loss: 4.5454 - categorical_accuracy: 0.0117 - val_loss: 4.5121 - val_categorical_accuracy: 0.0187
Epoch 19/50
125/125 [==============================] - 67s - loss: 4.5479 - categorical_accuracy: 0.0113 - val_loss: 4.5181 - val_categorical_accuracy: 0.0094
Epoch 20/50
125/125 [==============================] - 64s - loss: 4.5488 - categorical_accuracy: 0.0101 - val_loss: 4.5210 - val_categorical_accuracy: 0.0152
Epoch 21/50
125/125 [==============================] - 68s - loss: 4.5466 - categorical_accuracy: 0.0120 - val_loss: 4.5201 - val_categorical_accuracy: 0.0159
Epoch 22/50
125/125 [==============================] - 63s - loss: 4.5490 - categorical_accuracy: 0.0106 - val_loss: 4.5198 - val_categorical_accuracy: 0.0157
Epoch 23/50
125/125 [==============================] - 64s - loss: 4.5455 - categorical_accuracy: 0.0122 - val_loss: 4.5164 - val_categorical_accuracy: 0.0149
Epoch 24/50
125/125 [==============================] - 67s - loss: 4.5472 - categorical_accuracy: 0.0091 - val_loss: 4.5179 - val_categorical_accuracy: 0.0122
Epoch 25/50
125/125 [==============================] - 64s - loss: 4.5484 - categorical_accuracy: 0.0112 - val_loss: 4.5219 - val_categorical_accuracy: 0.0141
Epoch 26/50
125/125 [==============================] - 63s - loss: 4.5470 - categorical_accuracy: 0.0131 - val_loss: 4.5220 - val_categorical_accuracy: 0.0129
Epoch 27/50
125/125 [==============================] - 61s - loss: 4.5446 - categorical_accuracy: 0.0112 - val_loss: 4.5136 - val_categorical_accuracy: 0.0143
Epoch 28/50
125/125 [==============================] - 61s - loss: 4.5486 - categorical_accuracy: 0.0124 - val_loss: 4.5136 - val_categorical_accuracy: 0.0129
Epoch 29/50
125/125 [==============================] - 62s - loss: 4.5468 - categorical_accuracy: 0.0132 - val_loss: 4.5199 - val_categorical_accuracy: 0.0262
Epoch 30/50
125/125 [==============================] - 64s - loss: 4.5463 - categorical_accuracy: 0.0126 - val_loss: 4.5194 - val_categorical_accuracy: 0.0240
Epoch 31/50
125/125 [==============================] - 63s - loss: 4.5483 - categorical_accuracy: 0.0099 - val_loss: 4.5182 - val_categorical_accuracy: 0.0157
Epoch 32/50
125/125 [==============================] - 62s - loss: 4.5465 - categorical_accuracy: 0.0096 - val_loss: 4.5184 - val_categorical_accuracy: 0.0097
Epoch 33/50
125/125 [==============================] - 70s - loss: 4.5466 - categorical_accuracy: 0.0114 - val_loss: 4.5164 - val_categorical_accuracy: 0.0152
Epoch 34/50
125/125 [==============================] - 61s - loss: 4.5453 - categorical_accuracy: 0.0109 - val_loss: 4.5163 - val_categorical_accuracy: 0.0129
Epoch 35/50
125/125 [==============================] - 66s - loss: 4.5489 - categorical_accuracy: 0.0112 - val_loss: 4.5257 - val_categorical_accuracy: 0.0135
Epoch 36/50
125/125 [==============================] - 63s - loss: 4.5439 - categorical_accuracy: 0.0120 - val_loss: 4.5165 - val_categorical_accuracy: 0.0035
Epoch 37/50
125/125 [==============================] - 61s - loss: 4.5437 - categorical_accuracy: 0.0118 - val_loss: 4.5145 - val_categorical_accuracy: 0.0010
Epoch 38/50
125/125 [==============================] - 66s - loss: 4.5497 - categorical_accuracy: 0.0120 - val_loss: 4.5111 - val_categorical_accuracy: 0.0139
Epoch 39/50
125/125 [==============================] - 62s - loss: 4.5493 - categorical_accuracy: 0.0098 - val_loss: 4.5208 - val_categorical_accuracy: 0.0129
Epoch 40/50
125/125 [==============================] - 63s - loss: 4.5446 - categorical_accuracy: 0.0132 - val_loss: 4.5206 - val_categorical_accuracy: 0.0143
Epoch 41/50
125/125 [==============================] - 63s - loss: 4.5469 - categorical_accuracy: 0.0120 - val_loss: 4.5201 - val_categorical_accuracy: 0.0134
Epoch 42/50
125/125 [==============================] - 71s - loss: 4.5446 - categorical_accuracy: 0.0109 - val_loss: 4.5154 - val_categorical_accuracy: 0.0157
Epoch 43/50
125/125 [==============================] - 66s - loss: 4.5471 - categorical_accuracy: 0.0112 - val_loss: 4.5222 - val_categorical_accuracy: 0.0144
Epoch 44/50
125/125 [==============================] - 62s - loss: 4.5479 - categorical_accuracy: 0.0117 - val_loss: 4.5137 - val_categorical_accuracy: 0.0169
Epoch 45/50
125/125 [==============================] - 64s - loss: 4.5439 - categorical_accuracy: 0.0114 - val_loss: 4.5191 - val_categorical_accuracy: 0.0160
Epoch 46/50
125/125 [==============================] - 62s - loss: 4.5489 - categorical_accuracy: 0.0136 - val_loss: 4.5170 - val_categorical_accuracy: 0.0116
Epoch 47/50
125/125 [==============================] - 66s - loss: 4.5492 - categorical_accuracy: 0.0079 - val_loss: 4.5164 - val_categorical_accuracy: 0.0101
Epoch 48/50
125/125 [==============================] - 62s - loss: 4.5441 - categorical_accuracy: 0.0119 - val_loss: 4.5187 - val_categorical_accuracy: 0.0140
Epoch 49/50
125/125 [==============================] - 66s - loss: 4.5461 - categorical_accuracy: 0.0102 - val_loss: 4.5174 - val_categorical_accuracy: 0.0139
Epoch 50/50
125/125 [==============================] - 63s - loss: 4.5483 - categorical_accuracy: 0.0097 - val_loss: 4.5137 - val_categorical_accuracy: 0.0158
----------------------

Process finished with exit code 0

vgg16 model loss 1.1+ 测评成绩 0.4963 与验证集基本类似，过拟合需要解决，训练集做了中心化，但是测试集没有
resnet_2 只训练全连接层的参数
resnet_2_conv 在resnet的基础上训练了后面3个卷积层
上述方法由于使用了max pooling，而且接入两层全连接，且使用了0.5的drouout，效果不好 0.3644

resnet_3 改为avg pooling，直接接入一层全连接，训练后面三个卷积层和全连接，不使用drouout 0.3115
resnet_4 配置与上述相同， batchsize使用了256，使用了所有的数据训练，这样shuffle作用更强 0.2896
resnet101 效果与50基本相同，没有大幅提升

bilinear vgg16 0.26



____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
input_1 (InputLayer)             (None, None, None, 3) 0
____________________________________________________________________________________________________
block1_conv1 (Conv2D)            (None, None, None, 32 864         input_1[0][0]
____________________________________________________________________________________________________
block1_conv1_bn (BatchNormalizat (None, None, None, 32 128         block1_conv1[0][0]
____________________________________________________________________________________________________
block1_conv1_act (Activation)    (None, None, None, 32 0           block1_conv1_bn[0][0]
____________________________________________________________________________________________________
block1_conv2 (Conv2D)            (None, None, None, 64 18432       block1_conv1_act[0][0]
____________________________________________________________________________________________________
block1_conv2_bn (BatchNormalizat (None, None, None, 64 256         block1_conv2[0][0]
____________________________________________________________________________________________________
block1_conv2_act (Activation)    (None, None, None, 64 0           block1_conv2_bn[0][0]
____________________________________________________________________________________________________
block2_sepconv1 (SeparableConv2D (None, None, None, 12 8768        block1_conv2_act[0][0]
____________________________________________________________________________________________________
block2_sepconv1_bn (BatchNormali (None, None, None, 12 512         block2_sepconv1[0][0]
____________________________________________________________________________________________________
block2_sepconv2_act (Activation) (None, None, None, 12 0           block2_sepconv1_bn[0][0]
____________________________________________________________________________________________________
block2_sepconv2 (SeparableConv2D (None, None, None, 12 17536       block2_sepconv2_act[0][0]
____________________________________________________________________________________________________
block2_sepconv2_bn (BatchNormali (None, None, None, 12 512         block2_sepconv2[0][0]
____________________________________________________________________________________________________
conv2d_1 (Conv2D)                (None, None, None, 12 8192        block1_conv2_act[0][0]
____________________________________________________________________________________________________
block2_pool (MaxPooling2D)       (None, None, None, 12 0           block2_sepconv2_bn[0][0]
____________________________________________________________________________________________________
batch_normalization_1 (BatchNorm (None, None, None, 12 512         conv2d_1[0][0]
____________________________________________________________________________________________________
add_1 (Add)                      (None, None, None, 12 0           block2_pool[0][0]
                                                                   batch_normalization_1[0][0]
____________________________________________________________________________________________________
block3_sepconv1_act (Activation) (None, None, None, 12 0           add_1[0][0]
____________________________________________________________________________________________________
block3_sepconv1 (SeparableConv2D (None, None, None, 25 33920       block3_sepconv1_act[0][0]
____________________________________________________________________________________________________
block3_sepconv1_bn (BatchNormali (None, None, None, 25 1024        block3_sepconv1[0][0]
____________________________________________________________________________________________________
block3_sepconv2_act (Activation) (None, None, None, 25 0           block3_sepconv1_bn[0][0]
____________________________________________________________________________________________________
block3_sepconv2 (SeparableConv2D (None, None, None, 25 67840       block3_sepconv2_act[0][0]
____________________________________________________________________________________________________
block3_sepconv2_bn (BatchNormali (None, None, None, 25 1024        block3_sepconv2[0][0]
____________________________________________________________________________________________________
conv2d_2 (Conv2D)                (None, None, None, 25 32768       add_1[0][0]
____________________________________________________________________________________________________
block3_pool (MaxPooling2D)       (None, None, None, 25 0           block3_sepconv2_bn[0][0]
____________________________________________________________________________________________________
batch_normalization_2 (BatchNorm (None, None, None, 25 1024        conv2d_2[0][0]
____________________________________________________________________________________________________
add_2 (Add)                      (None, None, None, 25 0           block3_pool[0][0]
                                                                   batch_normalization_2[0][0]
____________________________________________________________________________________________________
block4_sepconv1_act (Activation) (None, None, None, 25 0           add_2[0][0]
____________________________________________________________________________________________________
block4_sepconv1 (SeparableConv2D (None, None, None, 72 188672      block4_sepconv1_act[0][0]
____________________________________________________________________________________________________
block4_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block4_sepconv1[0][0]
____________________________________________________________________________________________________
block4_sepconv2_act (Activation) (None, None, None, 72 0           block4_sepconv1_bn[0][0]
____________________________________________________________________________________________________
block4_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block4_sepconv2_act[0][0]
____________________________________________________________________________________________________
block4_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block4_sepconv2[0][0]
____________________________________________________________________________________________________
conv2d_3 (Conv2D)                (None, None, None, 72 186368      add_2[0][0]
____________________________________________________________________________________________________
block4_pool (MaxPooling2D)       (None, None, None, 72 0           block4_sepconv2_bn[0][0]
____________________________________________________________________________________________________
batch_normalization_3 (BatchNorm (None, None, None, 72 2912        conv2d_3[0][0]
____________________________________________________________________________________________________
add_3 (Add)                      (None, None, None, 72 0           block4_pool[0][0]
                                                                   batch_normalization_3[0][0]
____________________________________________________________________________________________________
block5_sepconv1_act (Activation) (None, None, None, 72 0           add_3[0][0]
____________________________________________________________________________________________________
block5_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block5_sepconv1_act[0][0]
____________________________________________________________________________________________________
block5_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block5_sepconv1[0][0]
____________________________________________________________________________________________________
block5_sepconv2_act (Activation) (None, None, None, 72 0           block5_sepconv1_bn[0][0]
____________________________________________________________________________________________________
block5_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block5_sepconv2_act[0][0]
____________________________________________________________________________________________________
block5_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block5_sepconv2[0][0]
____________________________________________________________________________________________________
block5_sepconv3_act (Activation) (None, None, None, 72 0           block5_sepconv2_bn[0][0]
____________________________________________________________________________________________________
block5_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block5_sepconv3_act[0][0]
____________________________________________________________________________________________________
block5_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block5_sepconv3[0][0]
____________________________________________________________________________________________________
add_4 (Add)                      (None, None, None, 72 0           block5_sepconv3_bn[0][0]
                                                                   add_3[0][0]
____________________________________________________________________________________________________
block6_sepconv1_act (Activation) (None, None, None, 72 0           add_4[0][0]
____________________________________________________________________________________________________
block6_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block6_sepconv1_act[0][0]
____________________________________________________________________________________________________
block6_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block6_sepconv1[0][0]
____________________________________________________________________________________________________
block6_sepconv2_act (Activation) (None, None, None, 72 0           block6_sepconv1_bn[0][0]
____________________________________________________________________________________________________
block6_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block6_sepconv2_act[0][0]
____________________________________________________________________________________________________
block6_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block6_sepconv2[0][0]
____________________________________________________________________________________________________
block6_sepconv3_act (Activation) (None, None, None, 72 0           block6_sepconv2_bn[0][0]
____________________________________________________________________________________________________
block6_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block6_sepconv3_act[0][0]
____________________________________________________________________________________________________
block6_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block6_sepconv3[0][0]
____________________________________________________________________________________________________
add_5 (Add)                      (None, None, None, 72 0           block6_sepconv3_bn[0][0]
                                                                   add_4[0][0]
____________________________________________________________________________________________________
block7_sepconv1_act (Activation) (None, None, None, 72 0           add_5[0][0]
____________________________________________________________________________________________________
block7_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block7_sepconv1_act[0][0]
____________________________________________________________________________________________________
block7_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block7_sepconv1[0][0]
____________________________________________________________________________________________________
block7_sepconv2_act (Activation) (None, None, None, 72 0           block7_sepconv1_bn[0][0]
____________________________________________________________________________________________________
block7_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block7_sepconv2_act[0][0]
____________________________________________________________________________________________________
block7_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block7_sepconv2[0][0]
____________________________________________________________________________________________________
block7_sepconv3_act (Activation) (None, None, None, 72 0           block7_sepconv2_bn[0][0]
____________________________________________________________________________________________________
block7_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block7_sepconv3_act[0][0]
____________________________________________________________________________________________________
block7_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block7_sepconv3[0][0]
____________________________________________________________________________________________________
add_6 (Add)                      (None, None, None, 72 0           block7_sepconv3_bn[0][0]
                                                                   add_5[0][0]
____________________________________________________________________________________________________
block8_sepconv1_act (Activation) (None, None, None, 72 0           add_6[0][0]
____________________________________________________________________________________________________
block8_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block8_sepconv1_act[0][0]
____________________________________________________________________________________________________
block8_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block8_sepconv1[0][0]
____________________________________________________________________________________________________
block8_sepconv2_act (Activation) (None, None, None, 72 0           block8_sepconv1_bn[0][0]
____________________________________________________________________________________________________
block8_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block8_sepconv2_act[0][0]
____________________________________________________________________________________________________
block8_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block8_sepconv2[0][0]
____________________________________________________________________________________________________
block8_sepconv3_act (Activation) (None, None, None, 72 0           block8_sepconv2_bn[0][0]
____________________________________________________________________________________________________
block8_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block8_sepconv3_act[0][0]
____________________________________________________________________________________________________
block8_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block8_sepconv3[0][0]
____________________________________________________________________________________________________
add_7 (Add)                      (None, None, None, 72 0           block8_sepconv3_bn[0][0]
                                                                   add_6[0][0]
____________________________________________________________________________________________________
block9_sepconv1_act (Activation) (None, None, None, 72 0           add_7[0][0]
____________________________________________________________________________________________________
block9_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block9_sepconv1_act[0][0]
____________________________________________________________________________________________________
block9_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block9_sepconv1[0][0]
____________________________________________________________________________________________________
block9_sepconv2_act (Activation) (None, None, None, 72 0           block9_sepconv1_bn[0][0]
____________________________________________________________________________________________________
block9_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block9_sepconv2_act[0][0]
____________________________________________________________________________________________________
block9_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block9_sepconv2[0][0]
____________________________________________________________________________________________________
block9_sepconv3_act (Activation) (None, None, None, 72 0           block9_sepconv2_bn[0][0]
____________________________________________________________________________________________________
block9_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block9_sepconv3_act[0][0]
____________________________________________________________________________________________________
block9_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block9_sepconv3[0][0]
____________________________________________________________________________________________________
add_8 (Add)                      (None, None, None, 72 0           block9_sepconv3_bn[0][0]
                                                                   add_7[0][0]
____________________________________________________________________________________________________
block10_sepconv1_act (Activation (None, None, None, 72 0           add_8[0][0]
____________________________________________________________________________________________________
block10_sepconv1 (SeparableConv2 (None, None, None, 72 536536      block10_sepconv1_act[0][0]
____________________________________________________________________________________________________
block10_sepconv1_bn (BatchNormal (None, None, None, 72 2912        block10_sepconv1[0][0]
____________________________________________________________________________________________________
block10_sepconv2_act (Activation (None, None, None, 72 0           block10_sepconv1_bn[0][0]
____________________________________________________________________________________________________
block10_sepconv2 (SeparableConv2 (None, None, None, 72 536536      block10_sepconv2_act[0][0]
____________________________________________________________________________________________________
block10_sepconv2_bn (BatchNormal (None, None, None, 72 2912        block10_sepconv2[0][0]
____________________________________________________________________________________________________
block10_sepconv3_act (Activation (None, None, None, 72 0           block10_sepconv2_bn[0][0]
____________________________________________________________________________________________________
block10_sepconv3 (SeparableConv2 (None, None, None, 72 536536      block10_sepconv3_act[0][0]
____________________________________________________________________________________________________
block10_sepconv3_bn (BatchNormal (None, None, None, 72 2912        block10_sepconv3[0][0]
____________________________________________________________________________________________________
add_9 (Add)                      (None, None, None, 72 0           block10_sepconv3_bn[0][0]
                                                                   add_8[0][0]
____________________________________________________________________________________________________
block11_sepconv1_act (Activation (None, None, None, 72 0           add_9[0][0]
____________________________________________________________________________________________________
block11_sepconv1 (SeparableConv2 (None, None, None, 72 536536      block11_sepconv1_act[0][0]
____________________________________________________________________________________________________
block11_sepconv1_bn (BatchNormal (None, None, None, 72 2912        block11_sepconv1[0][0]
____________________________________________________________________________________________________
block11_sepconv2_act (Activation (None, None, None, 72 0           block11_sepconv1_bn[0][0]
____________________________________________________________________________________________________
block11_sepconv2 (SeparableConv2 (None, None, None, 72 536536      block11_sepconv2_act[0][0]
____________________________________________________________________________________________________
block11_sepconv2_bn (BatchNormal (None, None, None, 72 2912        block11_sepconv2[0][0]
____________________________________________________________________________________________________
block11_sepconv3_act (Activation (None, None, None, 72 0           block11_sepconv2_bn[0][0]
____________________________________________________________________________________________________
block11_sepconv3 (SeparableConv2 (None, None, None, 72 536536      block11_sepconv3_act[0][0]
____________________________________________________________________________________________________
block11_sepconv3_bn (BatchNormal (None, None, None, 72 2912        block11_sepconv3[0][0]
____________________________________________________________________________________________________
add_10 (Add)                     (None, None, None, 72 0           block11_sepconv3_bn[0][0]
                                                                   add_9[0][0]
____________________________________________________________________________________________________
block12_sepconv1_act (Activation (None, None, None, 72 0           add_10[0][0]
____________________________________________________________________________________________________
block12_sepconv1 (SeparableConv2 (None, None, None, 72 536536      block12_sepconv1_act[0][0]
____________________________________________________________________________________________________
block12_sepconv1_bn (BatchNormal (None, None, None, 72 2912        block12_sepconv1[0][0]
____________________________________________________________________________________________________
block12_sepconv2_act (Activation (None, None, None, 72 0           block12_sepconv1_bn[0][0]
____________________________________________________________________________________________________
block12_sepconv2 (SeparableConv2 (None, None, None, 72 536536      block12_sepconv2_act[0][0]
____________________________________________________________________________________________________
block12_sepconv2_bn (BatchNormal (None, None, None, 72 2912        block12_sepconv2[0][0]
____________________________________________________________________________________________________
block12_sepconv3_act (Activation (None, None, None, 72 0           block12_sepconv2_bn[0][0]
____________________________________________________________________________________________________
block12_sepconv3 (SeparableConv2 (None, None, None, 72 536536      block12_sepconv3_act[0][0]
____________________________________________________________________________________________________
block12_sepconv3_bn (BatchNormal (None, None, None, 72 2912        block12_sepconv3[0][0]
____________________________________________________________________________________________________
add_11 (Add)                     (None, None, None, 72 0           block12_sepconv3_bn[0][0]
                                                                   add_10[0][0]
____________________________________________________________________________________________________
block13_sepconv1_act (Activation (None, None, None, 72 0           add_11[0][0]
____________________________________________________________________________________________________
block13_sepconv1 (SeparableConv2 (None, None, None, 72 536536      block13_sepconv1_act[0][0]
____________________________________________________________________________________________________
block13_sepconv1_bn (BatchNormal (None, None, None, 72 2912        block13_sepconv1[0][0]
____________________________________________________________________________________________________
block13_sepconv2_act (Activation (None, None, None, 72 0           block13_sepconv1_bn[0][0]
____________________________________________________________________________________________________
block13_sepconv2 (SeparableConv2 (None, None, None, 10 752024      block13_sepconv2_act[0][0]
____________________________________________________________________________________________________
block13_sepconv2_bn (BatchNormal (None, None, None, 10 4096        block13_sepconv2[0][0]
____________________________________________________________________________________________________
conv2d_4 (Conv2D)                (None, None, None, 10 745472      add_11[0][0]
____________________________________________________________________________________________________
block13_pool (MaxPooling2D)      (None, None, None, 10 0           block13_sepconv2_bn[0][0]
____________________________________________________________________________________________________
batch_normalization_4 (BatchNorm (None, None, None, 10 4096        conv2d_4[0][0]
____________________________________________________________________________________________________
add_12 (Add)                     (None, None, None, 10 0           block13_pool[0][0]
                                                                   batch_normalization_4[0][0]
____________________________________________________________________________________________________
block14_sepconv1 (SeparableConv2 (None, None, None, 15 1582080     add_12[0][0]
____________________________________________________________________________________________________
block14_sepconv1_bn (BatchNormal (None, None, None, 15 6144        block14_sepconv1[0][0]
____________________________________________________________________________________________________
block14_sepconv1_act (Activation (None, None, None, 15 0           block14_sepconv1_bn[0][0]
____________________________________________________________________________________________________
block14_sepconv2 (SeparableConv2 (None, None, None, 20 3159552     block14_sepconv1_act[0][0]
____________________________________________________________________________________________________
block14_sepconv2_bn (BatchNormal (None, None, None, 20 8192        block14_sepconv2[0][0]
____________________________________________________________________________________________________
block14_sepconv2_act (Activation (None, None, None, 20 0           block14_sepconv2_bn[0][0]
____________________________________________________________________________________________________
global_average_pooling2d_1 (Glob (None, 2048)          0           block14_sepconv2_act[0][0]
====================================================================================================
Total params: 20,861,480
Trainable params: 20,806,952
Non-trainable params: 54,528
____________________________________________________________________________________________________

xception_crop_1 train训练
xception_crop_2 全数据训练，目前效果最好，线上0.21
xception_crop_2 加入层冻结